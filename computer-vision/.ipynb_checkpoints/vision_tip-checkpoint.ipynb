{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vision/deep-learing 관련 꿀팁\n",
    "\n",
    "## 1. why max pooling?\n",
    "- 이미지 사이즈 줄이기 위해서\n",
    "- CNN scale-variant : 모델에서 적용된 사이즈와 이미지 사이즈가 같아야 함\n",
    "- max pooling 이 완화 : 성능을 유지하면서 사이즈를 조절\n",
    "\n",
    "## 2. Network Capacity tradeoff\n",
    "- 단순히 network를 깊게 쌓으면 성능이 줄어듦\n",
    "- (-) vanishing gradient problem 발생\n",
    "- (-) overfitting\n",
    "\n",
    "## 3. why Residual Block?\n",
    "- (+) vanishing gradient 완화 <- skip connection\n",
    "- (+) deeeeeep layer, ex) 101 layer of ResNet\n",
    "\n",
    "## 4. Randomness\n",
    "- pytorch나 numpy는 기본적으로 randomness를 가지고 있고, 이를 control할 수 있으면 좋다\n",
    "\n",
    "## 5. CNN magic number\n",
    "- image 사이즈를 보존하는 kernel size, padding, stride 조합\n",
    "- kernel size: 3, padding: 1, stride: 1\n",
    "- kernel size: 5, padding: 2, stride: 1\n",
    "- kernel size: 7, padding: 3, stride: 1\n",
    "\n",
    "## 6. momentum \n",
    "- loss가 떨어지는 방향을 유지\n",
    "- 1에 가까울수록 이전 값들에 둔감하게\n",
    "- SGD w/ momentum vs. Adam (image vision task의 경우 SGD w/ momentum 성능이 더 좋아)\n",
    "\n",
    "## 7. optimizer.zero_grad vs. net.zero_grad\n",
    "- optimizer가 input으로 net.parameter를 받았으면 똑같음\n",
    "\n",
    "## 8. BatchNorm, Normalization ...\n",
    "\n",
    "## 9. why sigmoid?\n",
    "- entropy loss사용할 때, 0 ~ 1 사이의 값을 넣어줘야하기 때문\n",
    "- binary classification에서 항상 사용\n",
    "\n",
    "## 10. transfer learning 방법\n",
    "- 비슷한 데이터셋 & 작은 데이터셋 : 마지막 부분 + classifier 트레이닝 (앞부분 고정)\n",
    "- 다른 데이터셋 & 작은 데이터셋 : 앞부분 트레이닝 + classifier 트레이닝 (뒷부분 고정)\n",
    "- 큰 데이터셋: 네트워크 전체를 다시 fine-tuning\n",
    "- 참고) catastrophic forgetting (transfer learning시 주의할 것) -> 검색해서 찾아보기\n",
    "\n",
    "## 11. RCNN 계열 vs. YOLO 차이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cifar-10 과제 tip\n",
    "\n",
    "\n",
    "1. randomness, seed=4332\n",
    "\n",
    "2. 개선할 때 방향성\n",
    "\n",
    "  - Data augmentation\n",
    "    - (Horizontal flip, color transform, warping, ... torchvision.transforms)\n",
    "  - Optimizer\n",
    "    - (learning_rate, momentum, SGD vs. Adam)\n",
    "    - (scheduler - learning rate) \n",
    "    - CosineAnnealingLR -  시간에 따라 learning rate\n",
    "    - ReduceLROnPlateau - validation set을 둬서 수렴하는 것 같다 싶으면 learning rate 낮춰줌\n",
    "\n",
    "  - Network Architecture\n",
    "    - ResNet 18 50 101 152\n",
    "    - VGG\n",
    "    - WideResNet\n",
    "\n",
    "\n",
    " - Loss function 수정 (Not recommended)\n",
    "\n",
    " - Regularization Technique\n",
    "  - Dropout\n",
    "  - weight decay\n",
    "  - Ensemble\n",
    "  ...\n",
    "\n",
    "3. 추가) 관심있으신 분들 보세요.\n",
    " - Auto-augment\n",
    " - Steerable CNNs (e2cnn 등.. image에 rotation이 발생하여도 견고하게 classfication 수행해줌)\n",
    "    - CNNs - scale-variant & rotation-variant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
