{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Challange - 김영인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. wide resnet 50-2\n",
    "2. \\+ Data Augmentation(RandomResizedCrop, RandomHorizontalFlip)\n",
    "3. \\+ Data Normalize\n",
    "4. \\+ regularization(weight decay)\n",
    "5. \\+ Optimizer(momentum, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T02:13:07.305228Z",
     "start_time": "2020-10-08T02:13:06.650716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "random_seed = 4332\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device1 = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = device0\n",
    "print(f\"device: {device}\") if torch.cuda.is_available() else print(\"device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T02:13:07.494364Z",
     "start_time": "2020-10-08T02:13:07.482029Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "scheduler_step = 30\n",
    "scheduler_gamma = 0.2\n",
    "training_epochs = 100\n",
    "batch_size = 64\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T02:13:09.756175Z",
     "start_time": "2020-10-08T02:13:08.087328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(224), # data augmentation, 224: image size, ImageNet pretrained model에 맞추기 위해서 224 size로 설정\n",
    "     transforms.RandomHorizontalFlip(), # data augmentation, 좌우로 대칭\n",
    "     transforms.ToTensor(), # numpy array를 pytorch tensor로 바꿔주는 역할\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # dataset의 mean, std를 이용해서 -1~1 로 normalize\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "testloader = DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Define pretrained model and fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T02:13:13.326246Z",
     "start_time": "2020-10-08T02:13:12.103945Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(models.wide_resnet50_2(pretrained=True).fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T02:13:13.333986Z",
     "start_time": "2020-10-08T02:13:13.328254Z"
    }
   },
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(WideResNet, self).__init__()\n",
    "        self.resnet = models.wide_resnet50_2(pretrained=True)\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T02:13:22.230091Z",
     "start_time": "2020-10-08T02:13:18.051475Z"
    }
   },
   "outputs": [],
   "source": [
    "net = WideResNet()\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                      step_size = scheduler_step,\n",
    "                                      gamma = scheduler_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T04:10:03.448715Z",
     "start_time": "2020-10-08T02:13:25.078972Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 5.464\n",
      "[1,   200] loss: 2.750\n",
      "[1,   300] loss: 2.271\n",
      "[1,   400] loss: 2.183\n",
      "[1,   500] loss: 2.108\n",
      "[1,   600] loss: 2.056\n",
      "[1,   700] loss: 2.004\n",
      "[2,   100] loss: 1.896\n",
      "[2,   200] loss: 1.890\n",
      "[2,   300] loss: 1.845\n",
      "[2,   400] loss: 1.841\n",
      "[2,   500] loss: 1.798\n",
      "[2,   600] loss: 1.814\n",
      "[2,   700] loss: 1.902\n",
      "[3,   100] loss: 1.789\n",
      "[3,   200] loss: 1.730\n",
      "[3,   300] loss: 1.694\n",
      "[3,   400] loss: 1.660\n",
      "[3,   500] loss: 1.638\n",
      "[3,   600] loss: 1.607\n",
      "[3,   700] loss: 1.601\n",
      "[4,   100] loss: 1.535\n",
      "[4,   200] loss: 1.532\n",
      "[4,   300] loss: 1.510\n",
      "[4,   400] loss: 1.486\n",
      "[4,   500] loss: 1.455\n",
      "[4,   600] loss: 1.469\n",
      "[4,   700] loss: 1.447\n",
      "[5,   100] loss: 1.388\n",
      "[5,   200] loss: 1.400\n",
      "[5,   300] loss: 1.396\n",
      "[5,   400] loss: 1.362\n",
      "[5,   500] loss: 1.345\n",
      "[5,   600] loss: 1.389\n",
      "[5,   700] loss: 1.321\n",
      "[6,   100] loss: 1.325\n",
      "[6,   200] loss: 1.283\n",
      "[6,   300] loss: 1.289\n",
      "[6,   400] loss: 1.263\n",
      "[6,   500] loss: 1.287\n",
      "[6,   600] loss: 1.268\n",
      "[6,   700] loss: 1.245\n",
      "[7,   100] loss: 1.213\n",
      "[7,   200] loss: 1.196\n",
      "[7,   300] loss: 1.199\n",
      "[7,   400] loss: 1.205\n",
      "[7,   500] loss: 1.189\n",
      "[7,   600] loss: 1.168\n",
      "[7,   700] loss: 1.163\n",
      "[8,   100] loss: 1.124\n",
      "[8,   200] loss: 1.107\n",
      "[8,   300] loss: 1.122\n",
      "[8,   400] loss: 1.117\n",
      "[8,   500] loss: 1.109\n",
      "[8,   600] loss: 1.109\n",
      "[8,   700] loss: 1.081\n",
      "[9,   100] loss: 1.086\n",
      "[9,   200] loss: 1.065\n",
      "[9,   300] loss: 1.085\n",
      "[9,   400] loss: 1.064\n",
      "[9,   500] loss: 1.089\n",
      "[9,   600] loss: 1.034\n",
      "[9,   700] loss: 1.094\n",
      "[10,   100] loss: 1.066\n",
      "[10,   200] loss: 0.998\n",
      "[10,   300] loss: 1.056\n",
      "[10,   400] loss: 1.009\n",
      "[10,   500] loss: 1.040\n",
      "[10,   600] loss: 1.034\n",
      "[10,   700] loss: 1.003\n",
      "[11,   100] loss: 0.959\n",
      "[11,   200] loss: 1.010\n",
      "[11,   300] loss: 1.011\n",
      "[11,   400] loss: 0.998\n",
      "[11,   500] loss: 1.009\n",
      "[11,   600] loss: 1.009\n",
      "[11,   700] loss: 1.017\n",
      "[12,   100] loss: 0.975\n",
      "[12,   200] loss: 0.947\n",
      "[12,   300] loss: 0.976\n",
      "[12,   400] loss: 0.957\n",
      "[12,   500] loss: 0.987\n",
      "[12,   600] loss: 0.989\n",
      "[12,   700] loss: 0.948\n",
      "[13,   100] loss: 0.918\n",
      "[13,   200] loss: 0.949\n",
      "[13,   300] loss: 0.945\n",
      "[13,   400] loss: 0.975\n",
      "[13,   500] loss: 0.940\n",
      "[13,   600] loss: 0.972\n",
      "[13,   700] loss: 0.948\n",
      "[14,   100] loss: 0.880\n",
      "[14,   200] loss: 0.919\n",
      "[14,   300] loss: 0.911\n",
      "[14,   400] loss: 0.956\n",
      "[14,   500] loss: 0.923\n",
      "[14,   600] loss: 0.924\n",
      "[14,   700] loss: 0.943\n",
      "[15,   100] loss: 0.871\n",
      "[15,   200] loss: 0.912\n",
      "[15,   300] loss: 0.932\n",
      "[15,   400] loss: 0.905\n",
      "[15,   500] loss: 0.913\n",
      "[15,   600] loss: 0.935\n",
      "[15,   700] loss: 0.937\n",
      "[16,   100] loss: 0.853\n",
      "[16,   200] loss: 0.854\n",
      "[16,   300] loss: 0.930\n",
      "[16,   400] loss: 0.864\n",
      "[16,   500] loss: 0.951\n",
      "[16,   600] loss: 0.913\n",
      "[16,   700] loss: 0.904\n",
      "[17,   100] loss: 0.876\n",
      "[17,   200] loss: 0.874\n",
      "[17,   300] loss: 0.869\n",
      "[17,   400] loss: 0.905\n",
      "[17,   500] loss: 0.889\n",
      "[17,   600] loss: 0.892\n",
      "[17,   700] loss: 0.897\n",
      "[18,   100] loss: 0.846\n",
      "[18,   200] loss: 0.880\n",
      "[18,   300] loss: 0.877\n",
      "[18,   400] loss: 0.898\n",
      "[18,   500] loss: 0.888\n",
      "[18,   600] loss: 0.879\n",
      "[18,   700] loss: 0.861\n",
      "[19,   100] loss: 0.843\n",
      "[19,   200] loss: 0.873\n",
      "[19,   300] loss: 0.886\n",
      "[19,   400] loss: 0.878\n",
      "[19,   500] loss: 0.894\n",
      "[19,   600] loss: 0.884\n",
      "[19,   700] loss: 0.864\n",
      "[20,   100] loss: 0.807\n",
      "[20,   200] loss: 0.846\n",
      "[20,   300] loss: 0.874\n",
      "[20,   400] loss: 0.867\n",
      "[20,   500] loss: 0.851\n",
      "[20,   600] loss: 0.849\n",
      "[20,   700] loss: 0.883\n",
      "[21,   100] loss: 0.837\n",
      "[21,   200] loss: 0.825\n",
      "[21,   300] loss: 0.862\n",
      "[21,   400] loss: 0.846\n",
      "[21,   500] loss: 0.882\n",
      "[21,   600] loss: 0.846\n",
      "[21,   700] loss: 0.879\n",
      "[22,   100] loss: 0.843\n",
      "[22,   200] loss: 0.838\n",
      "[22,   300] loss: 0.820\n",
      "[22,   400] loss: 0.846\n",
      "[22,   500] loss: 0.872\n",
      "[22,   600] loss: 0.851\n",
      "[22,   700] loss: 0.853\n",
      "[23,   100] loss: 0.810\n",
      "[23,   200] loss: 0.819\n",
      "[23,   300] loss: 0.834\n",
      "[23,   400] loss: 0.843\n",
      "[23,   500] loss: 0.828\n",
      "[23,   600] loss: 0.834\n",
      "[23,   700] loss: 0.832\n",
      "[24,   100] loss: 0.796\n",
      "[24,   200] loss: 0.787\n",
      "[24,   300] loss: 0.851\n",
      "[24,   400] loss: 0.835\n",
      "[24,   500] loss: 0.848\n",
      "[24,   600] loss: 0.842\n",
      "[24,   700] loss: 0.871\n",
      "[25,   100] loss: 0.801\n",
      "[25,   200] loss: 0.799\n",
      "[25,   300] loss: 0.810\n",
      "[25,   400] loss: 0.805\n",
      "[25,   500] loss: 0.833\n",
      "[25,   600] loss: 0.850\n",
      "[25,   700] loss: 0.843\n",
      "[26,   100] loss: 0.808\n",
      "[26,   200] loss: 0.814\n",
      "[26,   300] loss: 0.816\n",
      "[26,   400] loss: 0.796\n",
      "[26,   500] loss: 0.844\n",
      "[26,   600] loss: 0.827\n",
      "[26,   700] loss: 0.823\n",
      "[27,   100] loss: 0.771\n",
      "[27,   200] loss: 0.809\n",
      "[27,   300] loss: 0.820\n",
      "[27,   400] loss: 0.795\n",
      "[27,   500] loss: 0.850\n",
      "[27,   600] loss: 0.828\n",
      "[27,   700] loss: 0.816\n",
      "[28,   100] loss: 0.789\n",
      "[28,   200] loss: 0.801\n",
      "[28,   300] loss: 0.828\n",
      "[28,   400] loss: 0.819\n",
      "[28,   500] loss: 0.794\n",
      "[28,   600] loss: 0.834\n",
      "[28,   700] loss: 0.804\n",
      "[29,   100] loss: 0.776\n",
      "[29,   200] loss: 0.784\n",
      "[29,   300] loss: 0.779\n",
      "[29,   400] loss: 0.809\n",
      "[29,   500] loss: 0.814\n",
      "[29,   600] loss: 0.809\n",
      "[29,   700] loss: 0.844\n",
      "[30,   100] loss: 0.778\n",
      "[30,   200] loss: 0.764\n",
      "[30,   300] loss: 0.802\n",
      "[30,   400] loss: 0.807\n",
      "[30,   500] loss: 0.811\n",
      "[30,   600] loss: 0.846\n",
      "[30,   700] loss: 0.811\n",
      "[31,   100] loss: 0.763\n",
      "[31,   200] loss: 0.818\n",
      "[31,   300] loss: 0.829\n",
      "[31,   400] loss: 0.794\n",
      "[31,   500] loss: 0.806\n",
      "[31,   600] loss: 0.826\n",
      "[31,   700] loss: 0.828\n",
      "[32,   100] loss: 0.756\n",
      "[32,   200] loss: 0.784\n",
      "[32,   300] loss: 0.792\n",
      "[32,   400] loss: 0.792\n",
      "[32,   500] loss: 0.800\n",
      "[32,   600] loss: 0.801\n",
      "[32,   700] loss: 0.827\n",
      "[33,   100] loss: 0.767\n",
      "[33,   200] loss: 0.770\n",
      "[33,   300] loss: 0.797\n",
      "[33,   400] loss: 0.813\n",
      "[33,   500] loss: 0.828\n",
      "[33,   600] loss: 0.815\n",
      "[33,   700] loss: 0.805\n",
      "[34,   100] loss: 0.740\n",
      "[34,   200] loss: 0.794\n",
      "[34,   300] loss: 0.781\n",
      "[34,   400] loss: 0.779\n",
      "[34,   500] loss: 0.817\n",
      "[34,   600] loss: 0.798\n",
      "[34,   700] loss: 0.814\n",
      "[35,   100] loss: 0.780\n",
      "[35,   200] loss: 0.783\n",
      "[35,   300] loss: 0.765\n",
      "[35,   400] loss: 0.812\n",
      "[35,   500] loss: 0.788\n",
      "[35,   600] loss: 0.819\n",
      "[35,   700] loss: 0.802\n",
      "[36,   100] loss: 0.788\n",
      "[36,   200] loss: 0.754\n",
      "[36,   300] loss: 0.769\n",
      "[36,   400] loss: 0.770\n",
      "[36,   500] loss: 0.821\n",
      "[36,   600] loss: 0.831\n",
      "[36,   700] loss: 0.790\n",
      "[37,   100] loss: 0.759\n",
      "[37,   200] loss: 0.765\n",
      "[37,   300] loss: 0.781\n",
      "[37,   400] loss: 0.779\n",
      "[37,   500] loss: 0.764\n",
      "[37,   600] loss: 0.782\n",
      "[37,   700] loss: 0.804\n",
      "[38,   100] loss: 0.760\n",
      "[38,   200] loss: 0.762\n",
      "[38,   300] loss: 0.785\n",
      "[38,   400] loss: 0.805\n",
      "[38,   500] loss: 0.783\n",
      "[38,   600] loss: 0.769\n",
      "[38,   700] loss: 0.803\n",
      "[39,   100] loss: 0.763\n",
      "[39,   200] loss: 0.759\n",
      "[39,   300] loss: 0.765\n",
      "[39,   400] loss: 0.778\n",
      "[39,   500] loss: 0.777\n",
      "[39,   600] loss: 0.777\n",
      "[39,   700] loss: 0.808\n",
      "[40,   100] loss: 0.723\n",
      "[40,   200] loss: 0.754\n",
      "[40,   300] loss: 0.787\n",
      "[40,   400] loss: 0.786\n",
      "[40,   500] loss: 0.761\n",
      "[40,   600] loss: 0.772\n",
      "[40,   700] loss: 0.823\n",
      "[41,   100] loss: 0.730\n",
      "[41,   200] loss: 0.735\n",
      "[41,   300] loss: 0.783\n",
      "[41,   400] loss: 0.771\n",
      "[41,   500] loss: 0.781\n",
      "[41,   600] loss: 0.783\n",
      "[41,   700] loss: 0.798\n",
      "[42,   100] loss: 0.763\n",
      "[42,   200] loss: 0.738\n",
      "[42,   300] loss: 0.759\n",
      "[42,   400] loss: 0.807\n",
      "[42,   500] loss: 0.786\n",
      "[42,   600] loss: 0.806\n",
      "[42,   700] loss: 0.775\n",
      "[43,   100] loss: 0.760\n",
      "[43,   200] loss: 0.750\n",
      "[43,   300] loss: 0.733\n",
      "[43,   400] loss: 0.773\n",
      "[43,   500] loss: 0.772\n",
      "[43,   600] loss: 0.810\n",
      "[43,   700] loss: 0.791\n",
      "[44,   100] loss: 0.757\n",
      "[44,   200] loss: 0.752\n",
      "[44,   300] loss: 0.776\n",
      "[44,   400] loss: 0.763\n",
      "[44,   500] loss: 0.796\n",
      "[44,   600] loss: 0.770\n",
      "[44,   700] loss: 0.778\n",
      "[45,   100] loss: 0.756\n",
      "[45,   200] loss: 0.756\n",
      "[45,   300] loss: 0.769\n",
      "[45,   400] loss: 0.772\n",
      "[45,   500] loss: 0.799\n",
      "[45,   600] loss: 0.755\n",
      "[45,   700] loss: 0.767\n",
      "[46,   100] loss: 0.758\n",
      "[46,   200] loss: 0.754\n",
      "[46,   300] loss: 0.771\n",
      "[46,   400] loss: 0.763\n",
      "[46,   500] loss: 0.772\n",
      "[46,   600] loss: 0.772\n",
      "[46,   700] loss: 0.801\n",
      "[47,   100] loss: 0.722\n",
      "[47,   200] loss: 0.731\n",
      "[47,   300] loss: 0.748\n",
      "[47,   400] loss: 0.781\n",
      "[47,   500] loss: 0.775\n",
      "[47,   600] loss: 0.786\n",
      "[47,   700] loss: 0.806\n",
      "[48,   100] loss: 0.726\n",
      "[48,   200] loss: 0.736\n",
      "[48,   300] loss: 0.739\n",
      "[48,   400] loss: 0.773\n",
      "[48,   500] loss: 0.764\n",
      "[48,   600] loss: 0.754\n",
      "[48,   700] loss: 0.758\n",
      "[49,   100] loss: 0.729\n",
      "[49,   200] loss: 0.728\n",
      "[49,   300] loss: 0.779\n",
      "[49,   400] loss: 0.774\n",
      "[49,   500] loss: 0.756\n",
      "[49,   600] loss: 0.773\n",
      "[49,   700] loss: 0.785\n",
      "[50,   100] loss: 0.740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50,   200] loss: 0.771\n",
      "[50,   300] loss: 0.728\n",
      "[50,   400] loss: 0.752\n",
      "[50,   500] loss: 0.774\n",
      "[50,   600] loss: 0.780\n",
      "[50,   700] loss: 0.759\n",
      "[51,   100] loss: 0.726\n",
      "[51,   200] loss: 0.738\n",
      "[51,   300] loss: 0.770\n",
      "[51,   400] loss: 0.748\n",
      "[51,   500] loss: 0.747\n",
      "[51,   600] loss: 0.774\n",
      "[51,   700] loss: 0.778\n",
      "[52,   100] loss: 0.745\n",
      "[52,   200] loss: 0.745\n",
      "[52,   300] loss: 0.772\n",
      "[52,   400] loss: 0.775\n",
      "[52,   500] loss: 0.740\n",
      "[52,   600] loss: 0.744\n",
      "[52,   700] loss: 0.751\n",
      "[53,   100] loss: 0.722\n",
      "[53,   200] loss: 0.731\n",
      "[53,   300] loss: 0.745\n",
      "[53,   400] loss: 0.742\n",
      "[53,   500] loss: 0.774\n",
      "[53,   600] loss: 0.773\n",
      "[53,   700] loss: 0.773\n",
      "[54,   100] loss: 0.753\n",
      "[54,   200] loss: 0.749\n",
      "[54,   300] loss: 0.732\n",
      "[54,   400] loss: 0.739\n",
      "[54,   500] loss: 0.755\n",
      "[54,   600] loss: 0.781\n",
      "[54,   700] loss: 0.765\n",
      "[55,   100] loss: 0.709\n",
      "[55,   200] loss: 0.739\n",
      "[55,   300] loss: 0.764\n",
      "[55,   400] loss: 0.772\n",
      "[55,   500] loss: 0.767\n",
      "[55,   600] loss: 0.778\n",
      "[55,   700] loss: 0.766\n",
      "[56,   100] loss: 0.719\n",
      "[56,   200] loss: 0.727\n",
      "[56,   300] loss: 0.762\n",
      "[56,   400] loss: 0.742\n",
      "[56,   500] loss: 0.741\n",
      "[56,   600] loss: 0.764\n",
      "[56,   700] loss: 0.769\n",
      "[57,   100] loss: 0.720\n",
      "[57,   200] loss: 0.732\n",
      "[57,   300] loss: 0.783\n",
      "[57,   400] loss: 0.747\n",
      "[57,   500] loss: 0.769\n",
      "[57,   600] loss: 0.756\n",
      "[57,   700] loss: 0.767\n",
      "[58,   100] loss: 0.703\n",
      "[58,   200] loss: 0.752\n",
      "[58,   300] loss: 0.725\n",
      "[58,   400] loss: 0.709\n",
      "[58,   500] loss: 0.749\n",
      "[58,   600] loss: 0.749\n",
      "[58,   700] loss: 0.763\n",
      "[59,   100] loss: 0.707\n",
      "[59,   200] loss: 0.742\n",
      "[59,   300] loss: 0.734\n",
      "[59,   400] loss: 0.743\n",
      "[59,   500] loss: 0.771\n",
      "[59,   600] loss: 0.789\n",
      "[59,   700] loss: 0.750\n",
      "[60,   100] loss: 0.716\n",
      "[60,   200] loss: 0.731\n",
      "[60,   300] loss: 0.710\n",
      "[60,   400] loss: 0.768\n",
      "[60,   500] loss: 0.758\n",
      "[60,   600] loss: 0.768\n",
      "[60,   700] loss: 0.751\n",
      "[61,   100] loss: 0.710\n",
      "[61,   200] loss: 0.719\n",
      "[61,   300] loss: 0.737\n",
      "[61,   400] loss: 0.753\n",
      "[61,   500] loss: 0.767\n",
      "[61,   600] loss: 0.749\n",
      "[61,   700] loss: 0.754\n",
      "[62,   100] loss: 0.697\n",
      "[62,   200] loss: 0.734\n",
      "[62,   300] loss: 0.739\n",
      "[62,   400] loss: 0.714\n",
      "[62,   500] loss: 0.740\n",
      "[62,   600] loss: 0.746\n",
      "[62,   700] loss: 0.778\n",
      "[63,   100] loss: 0.724\n",
      "[63,   200] loss: 0.730\n",
      "[63,   300] loss: 0.722\n",
      "[63,   400] loss: 0.729\n",
      "[63,   500] loss: 0.737\n",
      "[63,   600] loss: 0.754\n",
      "[63,   700] loss: 0.765\n",
      "[64,   100] loss: 0.726\n",
      "[64,   200] loss: 0.701\n",
      "[64,   300] loss: 0.737\n",
      "[64,   400] loss: 0.714\n",
      "[64,   500] loss: 0.780\n",
      "[64,   600] loss: 0.741\n",
      "[64,   700] loss: 0.802\n",
      "[65,   100] loss: 0.691\n",
      "[65,   200] loss: 0.717\n",
      "[65,   300] loss: 0.715\n",
      "[65,   400] loss: 0.722\n",
      "[65,   500] loss: 0.732\n",
      "[65,   600] loss: 0.755\n",
      "[65,   700] loss: 0.800\n",
      "[66,   100] loss: 0.746\n",
      "[66,   200] loss: 0.718\n",
      "[66,   300] loss: 0.732\n",
      "[66,   400] loss: 0.740\n",
      "[66,   500] loss: 0.744\n",
      "[66,   600] loss: 0.753\n",
      "[66,   700] loss: 0.763\n",
      "[67,   100] loss: 0.722\n",
      "[67,   200] loss: 0.714\n",
      "[67,   300] loss: 0.755\n",
      "[67,   400] loss: 0.725\n",
      "[67,   500] loss: 0.762\n",
      "[67,   600] loss: 0.754\n",
      "[67,   700] loss: 0.758\n",
      "[68,   100] loss: 0.703\n",
      "[68,   200] loss: 0.753\n",
      "[68,   300] loss: 0.721\n",
      "[68,   400] loss: 0.743\n",
      "[68,   500] loss: 0.728\n",
      "[68,   600] loss: 0.737\n",
      "[68,   700] loss: 0.786\n",
      "[69,   100] loss: 0.697\n",
      "[69,   200] loss: 0.726\n",
      "[69,   300] loss: 0.729\n",
      "[69,   400] loss: 0.744\n",
      "[69,   500] loss: 0.737\n",
      "[69,   600] loss: 0.766\n",
      "[69,   700] loss: 0.748\n",
      "[70,   100] loss: 0.682\n",
      "[70,   200] loss: 0.708\n",
      "[70,   300] loss: 0.737\n",
      "[70,   400] loss: 0.742\n",
      "[70,   500] loss: 0.746\n",
      "[70,   600] loss: 0.757\n",
      "[70,   700] loss: 0.762\n",
      "[71,   100] loss: 0.685\n",
      "[71,   200] loss: 0.713\n",
      "[71,   300] loss: 0.720\n",
      "[71,   400] loss: 0.736\n",
      "[71,   500] loss: 0.762\n",
      "[71,   600] loss: 0.757\n",
      "[71,   700] loss: 0.768\n",
      "[72,   100] loss: 0.725\n",
      "[72,   200] loss: 0.692\n",
      "[72,   300] loss: 0.732\n",
      "[72,   400] loss: 0.744\n",
      "[72,   500] loss: 0.751\n",
      "[72,   600] loss: 0.761\n",
      "[72,   700] loss: 0.789\n",
      "[73,   100] loss: 0.711\n",
      "[73,   200] loss: 0.713\n",
      "[73,   300] loss: 0.696\n",
      "[73,   400] loss: 0.735\n",
      "[73,   500] loss: 0.749\n",
      "[73,   600] loss: 0.720\n",
      "[73,   700] loss: 0.772\n",
      "[74,   100] loss: 0.656\n",
      "[74,   200] loss: 0.714\n",
      "[74,   300] loss: 0.714\n",
      "[74,   400] loss: 0.776\n",
      "[74,   500] loss: 0.750\n",
      "[74,   600] loss: 0.763\n",
      "[74,   700] loss: 0.731\n",
      "[75,   100] loss: 0.716\n",
      "[75,   200] loss: 0.714\n",
      "[75,   300] loss: 0.723\n",
      "[75,   400] loss: 0.732\n",
      "[75,   500] loss: 0.740\n",
      "[75,   600] loss: 0.795\n",
      "[75,   700] loss: 0.740\n",
      "[76,   100] loss: 0.710\n",
      "[76,   200] loss: 0.685\n",
      "[76,   300] loss: 0.704\n",
      "[76,   400] loss: 0.757\n",
      "[76,   500] loss: 0.723\n",
      "[76,   600] loss: 0.765\n",
      "[76,   700] loss: 0.746\n",
      "[77,   100] loss: 0.707\n",
      "[77,   200] loss: 0.737\n",
      "[77,   300] loss: 0.724\n",
      "[77,   400] loss: 0.740\n",
      "[77,   500] loss: 0.759\n",
      "[77,   600] loss: 0.727\n",
      "[77,   700] loss: 0.747\n",
      "[78,   100] loss: 0.673\n",
      "[78,   200] loss: 0.713\n",
      "[78,   300] loss: 0.728\n",
      "[78,   400] loss: 0.737\n",
      "[78,   500] loss: 0.749\n",
      "[78,   600] loss: 0.778\n",
      "[78,   700] loss: 0.744\n",
      "[79,   100] loss: 0.683\n",
      "[79,   200] loss: 0.723\n",
      "[79,   300] loss: 0.731\n",
      "[79,   400] loss: 0.733\n",
      "[79,   500] loss: 0.737\n",
      "[79,   600] loss: 0.753\n",
      "[79,   700] loss: 0.723\n",
      "[80,   100] loss: 0.729\n",
      "[80,   200] loss: 0.712\n",
      "[80,   300] loss: 0.721\n",
      "[80,   400] loss: 0.735\n",
      "[80,   500] loss: 0.717\n",
      "[80,   600] loss: 0.731\n",
      "[80,   700] loss: 0.759\n",
      "[81,   100] loss: 0.693\n",
      "[81,   200] loss: 0.724\n",
      "[81,   300] loss: 0.733\n",
      "[81,   400] loss: 0.735\n",
      "[81,   500] loss: 0.734\n",
      "[81,   600] loss: 0.728\n",
      "[81,   700] loss: 0.734\n",
      "[82,   100] loss: 0.693\n",
      "[82,   200] loss: 0.733\n",
      "[82,   300] loss: 0.726\n",
      "[82,   400] loss: 0.731\n",
      "[82,   500] loss: 0.763\n",
      "[82,   600] loss: 0.776\n",
      "[82,   700] loss: 0.762\n",
      "[83,   100] loss: 0.703\n",
      "[83,   200] loss: 0.687\n",
      "[83,   300] loss: 0.717\n",
      "[83,   400] loss: 0.751\n",
      "[83,   500] loss: 0.778\n",
      "[83,   600] loss: 0.758\n",
      "[83,   700] loss: 0.772\n",
      "[84,   100] loss: 0.702\n",
      "[84,   200] loss: 0.682\n",
      "[84,   300] loss: 0.742\n",
      "[84,   400] loss: 0.724\n",
      "[84,   500] loss: 0.754\n",
      "[84,   600] loss: 0.727\n",
      "[84,   700] loss: 0.762\n",
      "[85,   100] loss: 0.708\n",
      "[85,   200] loss: 0.676\n",
      "[85,   300] loss: 0.749\n",
      "[85,   400] loss: 0.719\n",
      "[85,   500] loss: 0.765\n",
      "[85,   600] loss: 0.727\n",
      "[85,   700] loss: 0.763\n",
      "[86,   100] loss: 0.706\n",
      "[86,   200] loss: 0.724\n",
      "[86,   300] loss: 0.705\n",
      "[86,   400] loss: 0.750\n",
      "[86,   500] loss: 0.744\n",
      "[86,   600] loss: 0.715\n",
      "[86,   700] loss: 0.741\n",
      "[87,   100] loss: 0.699\n",
      "[87,   200] loss: 0.729\n",
      "[87,   300] loss: 0.705\n",
      "[87,   400] loss: 0.758\n",
      "[87,   500] loss: 0.744\n",
      "[87,   600] loss: 0.735\n",
      "[87,   700] loss: 0.745\n",
      "[88,   100] loss: 0.700\n",
      "[88,   200] loss: 0.723\n",
      "[88,   300] loss: 0.697\n",
      "[88,   400] loss: 0.714\n",
      "[88,   500] loss: 0.724\n",
      "[88,   600] loss: 0.752\n",
      "[88,   700] loss: 0.765\n",
      "[89,   100] loss: 0.661\n",
      "[89,   200] loss: 0.724\n",
      "[89,   300] loss: 0.714\n",
      "[89,   400] loss: 0.753\n",
      "[89,   500] loss: 0.752\n",
      "[89,   600] loss: 0.729\n",
      "[89,   700] loss: 0.734\n",
      "[90,   100] loss: 0.728\n",
      "[90,   200] loss: 0.688\n",
      "[90,   300] loss: 0.771\n",
      "[90,   400] loss: 0.739\n",
      "[90,   500] loss: 0.713\n",
      "[90,   600] loss: 0.726\n",
      "[90,   700] loss: 0.753\n",
      "[91,   100] loss: 0.696\n",
      "[91,   200] loss: 0.707\n",
      "[91,   300] loss: 0.718\n",
      "[91,   400] loss: 0.728\n",
      "[91,   500] loss: 0.725\n",
      "[91,   600] loss: 0.752\n",
      "[91,   700] loss: 0.747\n",
      "[92,   100] loss: 0.721\n",
      "[92,   200] loss: 0.702\n",
      "[92,   300] loss: 0.722\n",
      "[92,   400] loss: 0.729\n",
      "[92,   500] loss: 0.730\n",
      "[92,   600] loss: 0.731\n",
      "[92,   700] loss: 0.743\n",
      "[93,   100] loss: 0.678\n",
      "[93,   200] loss: 0.704\n",
      "[93,   300] loss: 0.732\n",
      "[93,   400] loss: 0.742\n",
      "[93,   500] loss: 0.735\n",
      "[93,   600] loss: 0.763\n",
      "[93,   700] loss: 0.742\n",
      "[94,   100] loss: 0.677\n",
      "[94,   200] loss: 0.746\n",
      "[94,   300] loss: 0.737\n",
      "[94,   400] loss: 0.723\n",
      "[94,   500] loss: 0.736\n",
      "[94,   600] loss: 0.726\n",
      "[94,   700] loss: 0.747\n",
      "[95,   100] loss: 0.726\n",
      "[95,   200] loss: 0.749\n",
      "[95,   300] loss: 0.733\n",
      "[95,   400] loss: 0.711\n",
      "[95,   500] loss: 0.719\n",
      "[95,   600] loss: 0.724\n",
      "[95,   700] loss: 0.726\n",
      "[96,   100] loss: 0.692\n",
      "[96,   200] loss: 0.699\n",
      "[96,   300] loss: 0.726\n",
      "[96,   400] loss: 0.729\n",
      "[96,   500] loss: 0.771\n",
      "[96,   600] loss: 0.760\n",
      "[96,   700] loss: 0.736\n",
      "[97,   100] loss: 0.714\n",
      "[97,   200] loss: 0.720\n",
      "[97,   300] loss: 0.745\n",
      "[97,   400] loss: 0.723\n",
      "[97,   500] loss: 0.741\n",
      "[97,   600] loss: 0.726\n",
      "[97,   700] loss: 0.744\n",
      "[98,   100] loss: 0.675\n",
      "[98,   200] loss: 0.710\n",
      "[98,   300] loss: 0.728\n",
      "[98,   400] loss: 0.721\n",
      "[98,   500] loss: 0.775\n",
      "[98,   600] loss: 0.739\n",
      "[98,   700] loss: 0.734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99,   100] loss: 0.668\n",
      "[99,   200] loss: 0.686\n",
      "[99,   300] loss: 0.695\n",
      "[99,   400] loss: 0.726\n",
      "[99,   500] loss: 0.739\n",
      "[99,   600] loss: 0.756\n",
      "[99,   700] loss: 0.763\n",
      "[100,   100] loss: 0.707\n",
      "[100,   200] loss: 0.715\n",
      "[100,   300] loss: 0.714\n",
      "[100,   400] loss: 0.732\n",
      "[100,   500] loss: 0.736\n",
      "[100,   600] loss: 0.748\n",
      "[100,   700] loss: 0.725\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs) \n",
    "        loss =  criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:02:30.562007Z",
     "start_time": "2020-10-08T05:02:02.772772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 94.500000 %\n",
      "Accuracy of   car : 75.000000 %\n",
      "Accuracy of  bird : 47.500000 %\n",
      "Accuracy of   cat : 38.000000 %\n",
      "Accuracy of  deer : 64.000000 %\n",
      "Accuracy of   dog : 10.400000 %\n",
      "Accuracy of  frog : 58.100000 %\n",
      "Accuracy of horse : 75.300000 %\n",
      "Accuracy of  ship : 45.600000 %\n",
      "Accuracy of truck : 64.700000 %\n",
      "Mean Accuracy :  57.31\n"
     ]
    }
   ],
   "source": [
    "class_correct = np.zeros(10)\n",
    "class_total = np.zeros(10)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print('Mean Accuracy : ', 100*np.sum(class_correct)/np.sum(class_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
