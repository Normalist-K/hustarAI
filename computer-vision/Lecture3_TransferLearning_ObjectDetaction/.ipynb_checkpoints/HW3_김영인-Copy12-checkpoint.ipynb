{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Challange - 김영인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. wide resnet 50-2\n",
    "2. \\+ Data Augmentation(RandomResizedCrop, RandomHorizontalFlip)\n",
    "3. \\+ Data Normalize\n",
    "5. \\+ Optimizer(momentum, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:03:33.343861Z",
     "start_time": "2020-10-08T05:03:32.712140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "random_seed = 4332\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device1 = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = device0\n",
    "print(f\"device: {device}\") if torch.cuda.is_available() else print(\"device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:03:33.348141Z",
     "start_time": "2020-10-08T05:03:33.345458Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "scheduler_step = 30\n",
    "scheduler_gamma = 0.2\n",
    "training_epochs = 100\n",
    "batch_size = 64\n",
    "momentum = 0.9\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:03:35.570605Z",
     "start_time": "2020-10-08T05:03:33.875443Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(224), # data augmentation, 224: image size, ImageNet pretrained model에 맞추기 위해서 224 size로 설정\n",
    "     transforms.RandomHorizontalFlip(), # data augmentation, 좌우로 대칭\n",
    "     transforms.ToTensor(), # numpy array를 pytorch tensor로 바꿔주는 역할\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # dataset의 mean, std를 이용해서 -1~1 로 normalize\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "testloader = DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Define pretrained model and fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:03:36.874587Z",
     "start_time": "2020-10-08T05:03:35.572194Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=2048, out_features=1000, bias=True)\n"
     ]
    }
   ],
   "source": [
    "print(models.wide_resnet50_2(pretrained=True).fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:03:36.880810Z",
     "start_time": "2020-10-08T05:03:36.876818Z"
    }
   },
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(WideResNet, self).__init__()\n",
    "        self.resnet = models.wide_resnet50_2(pretrained=True)\n",
    "        num_ftrs = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Linear(num_ftrs, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T05:03:41.289009Z",
     "start_time": "2020-10-08T05:03:36.882727Z"
    }
   },
   "outputs": [],
   "source": [
    "net = WideResNet()\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                      step_size = scheduler_step,\n",
    "                                      gamma = scheduler_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T06:58:38.168993Z",
     "start_time": "2020-10-08T05:03:41.290703Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 4.876\n",
      "[1,   200] loss: 2.744\n",
      "[1,   300] loss: 2.191\n",
      "[1,   400] loss: 2.072\n",
      "[1,   500] loss: 2.014\n",
      "[1,   600] loss: 1.993\n",
      "[1,   700] loss: 1.944\n",
      "[2,   100] loss: 1.865\n",
      "[2,   200] loss: 1.825\n",
      "[2,   300] loss: 1.798\n",
      "[2,   400] loss: 1.759\n",
      "[2,   500] loss: 1.705\n",
      "[2,   600] loss: 1.702\n",
      "[2,   700] loss: 1.663\n",
      "[3,   100] loss: 2.043\n",
      "[3,   200] loss: 1.727\n",
      "[3,   300] loss: 1.662\n",
      "[3,   400] loss: 1.624\n",
      "[3,   500] loss: 1.603\n",
      "[3,   600] loss: 1.582\n",
      "[3,   700] loss: 1.592\n",
      "[4,   100] loss: 1.502\n",
      "[4,   200] loss: 1.530\n",
      "[4,   300] loss: 1.504\n",
      "[4,   400] loss: 1.479\n",
      "[4,   500] loss: 1.458\n",
      "[4,   600] loss: 1.476\n",
      "[4,   700] loss: 1.468\n",
      "[5,   100] loss: 1.390\n",
      "[5,   200] loss: 1.426\n",
      "[5,   300] loss: 1.393\n",
      "[5,   400] loss: 1.377\n",
      "[5,   500] loss: 1.359\n",
      "[5,   600] loss: 1.386\n",
      "[5,   700] loss: 1.352\n",
      "[6,   100] loss: 1.352\n",
      "[6,   200] loss: 1.311\n",
      "[6,   300] loss: 1.330\n",
      "[6,   400] loss: 1.290\n",
      "[6,   500] loss: 1.341\n",
      "[6,   600] loss: 1.316\n",
      "[6,   700] loss: 1.292\n",
      "[7,   100] loss: 1.248\n",
      "[7,   200] loss: 1.239\n",
      "[7,   300] loss: 1.268\n",
      "[7,   400] loss: 1.261\n",
      "[7,   500] loss: 1.229\n",
      "[7,   600] loss: 1.238\n",
      "[7,   700] loss: 1.223\n",
      "[8,   100] loss: 1.245\n",
      "[8,   200] loss: 1.198\n",
      "[8,   300] loss: 1.198\n",
      "[8,   400] loss: 1.193\n",
      "[8,   500] loss: 1.204\n",
      "[8,   600] loss: 1.185\n",
      "[8,   700] loss: 1.150\n",
      "[9,   100] loss: 1.164\n",
      "[9,   200] loss: 1.153\n",
      "[9,   300] loss: 1.199\n",
      "[9,   400] loss: 1.132\n",
      "[9,   500] loss: 1.155\n",
      "[9,   600] loss: 1.156\n",
      "[9,   700] loss: 1.155\n",
      "[10,   100] loss: 1.124\n",
      "[10,   200] loss: 1.108\n",
      "[10,   300] loss: 1.137\n",
      "[10,   400] loss: 1.102\n",
      "[10,   500] loss: 1.093\n",
      "[10,   600] loss: 1.080\n",
      "[10,   700] loss: 1.090\n",
      "[11,   100] loss: 0.999\n",
      "[11,   200] loss: 1.052\n",
      "[11,   300] loss: 1.060\n",
      "[11,   400] loss: 1.049\n",
      "[11,   500] loss: 1.025\n",
      "[11,   600] loss: 1.016\n",
      "[11,   700] loss: 1.027\n",
      "[12,   100] loss: 0.996\n",
      "[12,   200] loss: 0.971\n",
      "[12,   300] loss: 0.993\n",
      "[12,   400] loss: 0.956\n",
      "[12,   500] loss: 0.993\n",
      "[12,   600] loss: 0.979\n",
      "[12,   700] loss: 0.980\n",
      "[13,   100] loss: 0.903\n",
      "[13,   200] loss: 0.928\n",
      "[13,   300] loss: 0.928\n",
      "[13,   400] loss: 0.923\n",
      "[13,   500] loss: 0.923\n",
      "[13,   600] loss: 0.949\n",
      "[13,   700] loss: 0.924\n",
      "[14,   100] loss: 0.854\n",
      "[14,   200] loss: 0.890\n",
      "[14,   300] loss: 0.873\n",
      "[14,   400] loss: 0.893\n",
      "[14,   500] loss: 0.886\n",
      "[14,   600] loss: 0.878\n",
      "[14,   700] loss: 0.885\n",
      "[15,   100] loss: 0.815\n",
      "[15,   200] loss: 0.828\n",
      "[15,   300] loss: 0.853\n",
      "[15,   400] loss: 0.805\n",
      "[15,   500] loss: 0.833\n",
      "[15,   600] loss: 0.861\n",
      "[15,   700] loss: 0.833\n",
      "[16,   100] loss: 0.765\n",
      "[16,   200] loss: 0.789\n",
      "[16,   300] loss: 0.837\n",
      "[16,   400] loss: 0.801\n",
      "[16,   500] loss: 0.830\n",
      "[16,   600] loss: 0.808\n",
      "[16,   700] loss: 0.791\n",
      "[17,   100] loss: 0.767\n",
      "[17,   200] loss: 0.751\n",
      "[17,   300] loss: 0.763\n",
      "[17,   400] loss: 0.766\n",
      "[17,   500] loss: 0.770\n",
      "[17,   600] loss: 0.772\n",
      "[17,   700] loss: 0.756\n",
      "[18,   100] loss: 0.747\n",
      "[18,   200] loss: 0.726\n",
      "[18,   300] loss: 0.815\n",
      "[18,   400] loss: 0.753\n",
      "[18,   500] loss: 0.723\n",
      "[18,   600] loss: 0.811\n",
      "[18,   700] loss: 0.728\n",
      "[19,   100] loss: 0.698\n",
      "[19,   200] loss: 0.708\n",
      "[19,   300] loss: 0.703\n",
      "[19,   400] loss: 0.696\n",
      "[19,   500] loss: 0.721\n",
      "[19,   600] loss: 0.704\n",
      "[19,   700] loss: 0.679\n",
      "[20,   100] loss: 0.710\n",
      "[20,   200] loss: 0.784\n",
      "[20,   300] loss: 0.705\n",
      "[20,   400] loss: 0.692\n",
      "[20,   500] loss: 0.680\n",
      "[20,   600] loss: 0.671\n",
      "[20,   700] loss: 0.678\n",
      "[21,   100] loss: 0.634\n",
      "[21,   200] loss: 0.609\n",
      "[21,   300] loss: 0.653\n",
      "[21,   400] loss: 0.638\n",
      "[21,   500] loss: 0.636\n",
      "[21,   600] loss: 0.628\n",
      "[21,   700] loss: 0.671\n",
      "[22,   100] loss: 0.578\n",
      "[22,   200] loss: 0.584\n",
      "[22,   300] loss: 0.571\n",
      "[22,   400] loss: 0.595\n",
      "[22,   500] loss: 0.613\n",
      "[22,   600] loss: 0.612\n",
      "[22,   700] loss: 0.612\n",
      "[23,   100] loss: 0.546\n",
      "[23,   200] loss: 0.558\n",
      "[23,   300] loss: 0.562\n",
      "[23,   400] loss: 0.573\n",
      "[23,   500] loss: 0.566\n",
      "[23,   600] loss: 0.596\n",
      "[23,   700] loss: 0.564\n",
      "[24,   100] loss: 0.519\n",
      "[24,   200] loss: 0.495\n",
      "[24,   300] loss: 0.563\n",
      "[24,   400] loss: 0.529\n",
      "[24,   500] loss: 0.565\n",
      "[24,   600] loss: 0.548\n",
      "[24,   700] loss: 0.569\n",
      "[25,   100] loss: 0.503\n",
      "[25,   200] loss: 0.500\n",
      "[25,   300] loss: 0.492\n",
      "[25,   400] loss: 0.508\n",
      "[25,   500] loss: 0.513\n",
      "[25,   600] loss: 0.516\n",
      "[25,   700] loss: 0.525\n",
      "[26,   100] loss: 0.446\n",
      "[26,   200] loss: 0.465\n",
      "[26,   300] loss: 0.476\n",
      "[26,   400] loss: 0.477\n",
      "[26,   500] loss: 0.489\n",
      "[26,   600] loss: 0.485\n",
      "[26,   700] loss: 0.503\n",
      "[27,   100] loss: 0.411\n",
      "[27,   200] loss: 0.434\n",
      "[27,   300] loss: 0.471\n",
      "[27,   400] loss: 0.451\n",
      "[27,   500] loss: 0.461\n",
      "[27,   600] loss: 0.464\n",
      "[27,   700] loss: 0.457\n",
      "[28,   100] loss: 0.401\n",
      "[28,   200] loss: 0.392\n",
      "[28,   300] loss: 0.416\n",
      "[28,   400] loss: 0.442\n",
      "[28,   500] loss: 0.434\n",
      "[28,   600] loss: 0.458\n",
      "[28,   700] loss: 0.431\n",
      "[29,   100] loss: 0.353\n",
      "[29,   200] loss: 0.374\n",
      "[29,   300] loss: 0.401\n",
      "[29,   400] loss: 0.398\n",
      "[29,   500] loss: 0.402\n",
      "[29,   600] loss: 0.396\n",
      "[29,   700] loss: 0.406\n",
      "[30,   100] loss: 0.334\n",
      "[30,   200] loss: 0.343\n",
      "[30,   300] loss: 0.369\n",
      "[30,   400] loss: 0.390\n",
      "[30,   500] loss: 0.389\n",
      "[30,   600] loss: 0.393\n",
      "[30,   700] loss: 0.438\n",
      "[31,   100] loss: 0.364\n",
      "[31,   200] loss: 0.358\n",
      "[31,   300] loss: 0.370\n",
      "[31,   400] loss: 0.345\n",
      "[31,   500] loss: 0.359\n",
      "[31,   600] loss: 0.346\n",
      "[31,   700] loss: 0.374\n",
      "[32,   100] loss: 0.274\n",
      "[32,   200] loss: 0.299\n",
      "[32,   300] loss: 0.322\n",
      "[32,   400] loss: 0.344\n",
      "[32,   500] loss: 0.323\n",
      "[32,   600] loss: 0.342\n",
      "[32,   700] loss: 0.343\n",
      "[33,   100] loss: 0.266\n",
      "[33,   200] loss: 0.288\n",
      "[33,   300] loss: 0.312\n",
      "[33,   400] loss: 0.320\n",
      "[33,   500] loss: 0.320\n",
      "[33,   600] loss: 0.332\n",
      "[33,   700] loss: 0.337\n",
      "[34,   100] loss: 0.252\n",
      "[34,   200] loss: 0.282\n",
      "[34,   300] loss: 0.286\n",
      "[34,   400] loss: 0.294\n",
      "[34,   500] loss: 0.284\n",
      "[34,   600] loss: 0.320\n",
      "[34,   700] loss: 0.300\n",
      "[35,   100] loss: 0.252\n",
      "[35,   200] loss: 0.254\n",
      "[35,   300] loss: 0.264\n",
      "[35,   400] loss: 0.267\n",
      "[35,   500] loss: 0.268\n",
      "[35,   600] loss: 0.296\n",
      "[35,   700] loss: 0.285\n",
      "[36,   100] loss: 0.240\n",
      "[36,   200] loss: 0.217\n",
      "[36,   300] loss: 0.250\n",
      "[36,   400] loss: 0.273\n",
      "[36,   500] loss: 0.271\n",
      "[36,   600] loss: 0.268\n",
      "[36,   700] loss: 0.258\n",
      "[37,   100] loss: 0.217\n",
      "[37,   200] loss: 0.220\n",
      "[37,   300] loss: 0.222\n",
      "[37,   400] loss: 0.221\n",
      "[37,   500] loss: 0.231\n",
      "[37,   600] loss: 0.223\n",
      "[37,   700] loss: 0.257\n",
      "[38,   100] loss: 0.188\n",
      "[38,   200] loss: 0.199\n",
      "[38,   300] loss: 0.236\n",
      "[38,   400] loss: 0.208\n",
      "[38,   500] loss: 0.215\n",
      "[38,   600] loss: 0.221\n",
      "[38,   700] loss: 0.248\n",
      "[39,   100] loss: 0.189\n",
      "[39,   200] loss: 0.182\n",
      "[39,   300] loss: 0.189\n",
      "[39,   400] loss: 0.211\n",
      "[39,   500] loss: 0.204\n",
      "[39,   600] loss: 0.196\n",
      "[39,   700] loss: 0.201\n",
      "[40,   100] loss: 0.158\n",
      "[40,   200] loss: 0.169\n",
      "[40,   300] loss: 0.180\n",
      "[40,   400] loss: 0.203\n",
      "[40,   500] loss: 0.203\n",
      "[40,   600] loss: 0.212\n",
      "[40,   700] loss: 0.212\n",
      "[41,   100] loss: 0.166\n",
      "[41,   200] loss: 0.154\n",
      "[41,   300] loss: 0.179\n",
      "[41,   400] loss: 0.159\n",
      "[41,   500] loss: 0.187\n",
      "[41,   600] loss: 0.195\n",
      "[41,   700] loss: 0.176\n",
      "[42,   100] loss: 0.150\n",
      "[42,   200] loss: 0.152\n",
      "[42,   300] loss: 0.169\n",
      "[42,   400] loss: 0.168\n",
      "[42,   500] loss: 0.172\n",
      "[42,   600] loss: 0.169\n",
      "[42,   700] loss: 0.175\n",
      "[43,   100] loss: 0.145\n",
      "[43,   200] loss: 0.147\n",
      "[43,   300] loss: 0.128\n",
      "[43,   400] loss: 0.154\n",
      "[43,   500] loss: 0.139\n",
      "[43,   600] loss: 0.174\n",
      "[43,   700] loss: 0.174\n",
      "[44,   100] loss: 0.129\n",
      "[44,   200] loss: 0.145\n",
      "[44,   300] loss: 0.148\n",
      "[44,   400] loss: 0.133\n",
      "[44,   500] loss: 0.151\n",
      "[44,   600] loss: 0.153\n",
      "[44,   700] loss: 0.150\n",
      "[45,   100] loss: 0.135\n",
      "[45,   200] loss: 0.121\n",
      "[45,   300] loss: 0.122\n",
      "[45,   400] loss: 0.110\n",
      "[45,   500] loss: 0.137\n",
      "[45,   600] loss: 0.131\n",
      "[45,   700] loss: 0.149\n",
      "[46,   100] loss: 0.117\n",
      "[46,   200] loss: 0.119\n",
      "[46,   300] loss: 0.121\n",
      "[46,   400] loss: 0.124\n",
      "[46,   500] loss: 0.143\n",
      "[46,   600] loss: 0.111\n",
      "[46,   700] loss: 0.131\n",
      "[47,   100] loss: 0.105\n",
      "[47,   200] loss: 0.103\n",
      "[47,   300] loss: 0.130\n",
      "[47,   400] loss: 0.121\n",
      "[47,   500] loss: 0.114\n",
      "[47,   600] loss: 0.128\n",
      "[47,   700] loss: 0.129\n",
      "[48,   100] loss: 0.128\n",
      "[48,   200] loss: 0.102\n",
      "[48,   300] loss: 0.114\n",
      "[48,   400] loss: 0.121\n",
      "[48,   500] loss: 0.113\n",
      "[48,   600] loss: 0.122\n",
      "[48,   700] loss: 0.104\n",
      "[49,   100] loss: 0.074\n",
      "[49,   200] loss: 0.104\n",
      "[49,   300] loss: 0.094\n",
      "[49,   400] loss: 0.110\n",
      "[49,   500] loss: 0.107\n",
      "[49,   600] loss: 0.118\n",
      "[49,   700] loss: 0.103\n",
      "[50,   100] loss: 0.075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50,   200] loss: 0.079\n",
      "[50,   300] loss: 0.084\n",
      "[50,   400] loss: 0.082\n",
      "[50,   500] loss: 0.089\n",
      "[50,   600] loss: 0.099\n",
      "[50,   700] loss: 0.102\n",
      "[51,   100] loss: 0.098\n",
      "[51,   200] loss: 0.072\n",
      "[51,   300] loss: 0.066\n",
      "[51,   400] loss: 0.071\n",
      "[51,   500] loss: 0.099\n",
      "[51,   600] loss: 0.088\n",
      "[51,   700] loss: 0.095\n",
      "[52,   100] loss: 0.092\n",
      "[52,   200] loss: 0.092\n",
      "[52,   300] loss: 0.086\n",
      "[52,   400] loss: 0.074\n",
      "[52,   500] loss: 0.099\n",
      "[52,   600] loss: 0.094\n",
      "[52,   700] loss: 0.074\n",
      "[53,   100] loss: 0.055\n",
      "[53,   200] loss: 0.066\n",
      "[53,   300] loss: 0.080\n",
      "[53,   400] loss: 0.079\n",
      "[53,   500] loss: 0.079\n",
      "[53,   600] loss: 0.086\n",
      "[53,   700] loss: 0.081\n",
      "[54,   100] loss: 0.127\n",
      "[54,   200] loss: 0.097\n",
      "[54,   300] loss: 0.074\n",
      "[54,   400] loss: 0.072\n",
      "[54,   500] loss: 0.074\n",
      "[54,   600] loss: 0.073\n",
      "[54,   700] loss: 0.081\n",
      "[55,   100] loss: 0.058\n",
      "[55,   200] loss: 0.063\n",
      "[55,   300] loss: 0.065\n",
      "[55,   400] loss: 0.080\n",
      "[55,   500] loss: 0.064\n",
      "[55,   600] loss: 0.063\n",
      "[55,   700] loss: 0.086\n",
      "[56,   100] loss: 0.082\n",
      "[56,   200] loss: 0.050\n",
      "[56,   300] loss: 0.066\n",
      "[56,   400] loss: 0.074\n",
      "[56,   500] loss: 0.073\n",
      "[56,   600] loss: 0.093\n",
      "[56,   700] loss: 0.061\n",
      "[57,   100] loss: 0.056\n",
      "[57,   200] loss: 0.047\n",
      "[57,   300] loss: 0.063\n",
      "[57,   400] loss: 0.062\n",
      "[57,   500] loss: 0.055\n",
      "[57,   600] loss: 0.055\n",
      "[57,   700] loss: 0.085\n",
      "[58,   100] loss: 0.044\n",
      "[58,   200] loss: 0.041\n",
      "[58,   300] loss: 0.045\n",
      "[58,   400] loss: 0.058\n",
      "[58,   500] loss: 0.059\n",
      "[58,   600] loss: 0.071\n",
      "[58,   700] loss: 0.068\n",
      "[59,   100] loss: 0.053\n",
      "[59,   200] loss: 0.046\n",
      "[59,   300] loss: 0.053\n",
      "[59,   400] loss: 0.047\n",
      "[59,   500] loss: 0.068\n",
      "[59,   600] loss: 0.062\n",
      "[59,   700] loss: 0.061\n",
      "[60,   100] loss: 0.050\n",
      "[60,   200] loss: 0.046\n",
      "[60,   300] loss: 0.051\n",
      "[60,   400] loss: 0.049\n",
      "[60,   500] loss: 0.050\n",
      "[60,   600] loss: 0.055\n",
      "[60,   700] loss: 0.053\n",
      "[61,   100] loss: 0.043\n",
      "[61,   200] loss: 0.036\n",
      "[61,   300] loss: 0.044\n",
      "[61,   400] loss: 0.056\n",
      "[61,   500] loss: 0.056\n",
      "[61,   600] loss: 0.055\n",
      "[61,   700] loss: 0.057\n",
      "[62,   100] loss: 0.025\n",
      "[62,   200] loss: 0.033\n",
      "[62,   300] loss: 0.058\n",
      "[62,   400] loss: 0.057\n",
      "[62,   500] loss: 0.041\n",
      "[62,   600] loss: 0.050\n",
      "[62,   700] loss: 0.047\n",
      "[63,   100] loss: 0.032\n",
      "[63,   200] loss: 0.038\n",
      "[63,   300] loss: 0.047\n",
      "[63,   400] loss: 0.046\n",
      "[63,   500] loss: 0.045\n",
      "[63,   600] loss: 0.050\n",
      "[63,   700] loss: 0.060\n",
      "[64,   100] loss: 0.054\n",
      "[64,   200] loss: 0.040\n",
      "[64,   300] loss: 0.032\n",
      "[64,   400] loss: 0.038\n",
      "[64,   500] loss: 0.040\n",
      "[64,   600] loss: 0.043\n",
      "[64,   700] loss: 0.044\n",
      "[65,   100] loss: 0.048\n",
      "[65,   200] loss: 0.042\n",
      "[65,   300] loss: 0.040\n",
      "[65,   400] loss: 0.034\n",
      "[65,   500] loss: 0.037\n",
      "[65,   600] loss: 0.050\n",
      "[65,   700] loss: 0.055\n",
      "[66,   100] loss: 0.050\n",
      "[66,   200] loss: 0.046\n",
      "[66,   300] loss: 0.042\n",
      "[66,   400] loss: 0.041\n",
      "[66,   500] loss: 0.041\n",
      "[66,   600] loss: 0.037\n",
      "[66,   700] loss: 0.045\n",
      "[67,   100] loss: 0.030\n",
      "[67,   200] loss: 0.027\n",
      "[67,   300] loss: 0.032\n",
      "[67,   400] loss: 0.030\n",
      "[67,   500] loss: 0.032\n",
      "[67,   600] loss: 0.046\n",
      "[67,   700] loss: 0.049\n",
      "[68,   100] loss: 0.024\n",
      "[68,   200] loss: 0.029\n",
      "[68,   300] loss: 0.033\n",
      "[68,   400] loss: 0.038\n",
      "[68,   500] loss: 0.033\n",
      "[68,   600] loss: 0.034\n",
      "[68,   700] loss: 0.038\n",
      "[69,   100] loss: 0.035\n",
      "[69,   200] loss: 0.037\n",
      "[69,   300] loss: 0.041\n",
      "[69,   400] loss: 0.048\n",
      "[69,   500] loss: 0.047\n",
      "[69,   600] loss: 0.032\n",
      "[69,   700] loss: 0.045\n",
      "[70,   100] loss: 0.035\n",
      "[70,   200] loss: 0.027\n",
      "[70,   300] loss: 0.027\n",
      "[70,   400] loss: 0.038\n",
      "[70,   500] loss: 0.038\n",
      "[70,   600] loss: 0.038\n",
      "[70,   700] loss: 0.042\n",
      "[71,   100] loss: 0.040\n",
      "[71,   200] loss: 0.021\n",
      "[71,   300] loss: 0.032\n",
      "[71,   400] loss: 0.030\n",
      "[71,   500] loss: 0.040\n",
      "[71,   600] loss: 0.042\n",
      "[71,   700] loss: 0.044\n",
      "[72,   100] loss: 0.030\n",
      "[72,   200] loss: 0.027\n",
      "[72,   300] loss: 0.026\n",
      "[72,   400] loss: 0.035\n",
      "[72,   500] loss: 0.043\n",
      "[72,   600] loss: 0.033\n",
      "[72,   700] loss: 0.035\n",
      "[73,   100] loss: 0.032\n",
      "[73,   200] loss: 0.025\n",
      "[73,   300] loss: 0.026\n",
      "[73,   400] loss: 0.033\n",
      "[73,   500] loss: 0.026\n",
      "[73,   600] loss: 0.039\n",
      "[73,   700] loss: 0.040\n",
      "[74,   100] loss: 0.024\n",
      "[74,   200] loss: 0.039\n",
      "[74,   300] loss: 0.031\n",
      "[74,   400] loss: 0.032\n",
      "[74,   500] loss: 0.038\n",
      "[74,   600] loss: 0.031\n",
      "[74,   700] loss: 0.060\n",
      "[75,   100] loss: 0.044\n",
      "[75,   200] loss: 0.026\n",
      "[75,   300] loss: 0.026\n",
      "[75,   400] loss: 0.039\n",
      "[75,   500] loss: 0.034\n",
      "[75,   600] loss: 0.028\n",
      "[75,   700] loss: 0.041\n",
      "[76,   100] loss: 0.028\n",
      "[76,   200] loss: 0.030\n",
      "[76,   300] loss: 0.032\n",
      "[76,   400] loss: 0.026\n",
      "[76,   500] loss: 0.029\n",
      "[76,   600] loss: 0.035\n",
      "[76,   700] loss: 0.024\n",
      "[77,   100] loss: 0.048\n",
      "[77,   200] loss: 0.038\n",
      "[77,   300] loss: 0.038\n",
      "[77,   400] loss: 0.028\n",
      "[77,   500] loss: 0.021\n",
      "[77,   600] loss: 0.025\n",
      "[77,   700] loss: 0.030\n",
      "[78,   100] loss: 0.030\n",
      "[78,   200] loss: 0.019\n",
      "[78,   300] loss: 0.027\n",
      "[78,   400] loss: 0.017\n",
      "[78,   500] loss: 0.022\n",
      "[78,   600] loss: 0.025\n",
      "[78,   700] loss: 0.034\n",
      "[79,   100] loss: 0.037\n",
      "[79,   200] loss: 0.032\n",
      "[79,   300] loss: 0.023\n",
      "[79,   400] loss: 0.022\n",
      "[79,   500] loss: 0.036\n",
      "[79,   600] loss: 0.029\n",
      "[79,   700] loss: 0.031\n",
      "[80,   100] loss: 0.020\n",
      "[80,   200] loss: 0.021\n",
      "[80,   300] loss: 0.017\n",
      "[80,   400] loss: 0.027\n",
      "[80,   500] loss: 0.026\n",
      "[80,   600] loss: 0.036\n",
      "[80,   700] loss: 0.030\n",
      "[81,   100] loss: 0.023\n",
      "[81,   200] loss: 0.023\n",
      "[81,   300] loss: 0.019\n",
      "[81,   400] loss: 0.022\n",
      "[81,   500] loss: 0.026\n",
      "[81,   600] loss: 0.037\n",
      "[81,   700] loss: 0.029\n",
      "[82,   100] loss: 0.023\n",
      "[82,   200] loss: 0.016\n",
      "[82,   300] loss: 0.022\n",
      "[82,   400] loss: 0.029\n",
      "[82,   500] loss: 0.019\n",
      "[82,   600] loss: 0.026\n",
      "[82,   700] loss: 0.019\n",
      "[83,   100] loss: 0.013\n",
      "[83,   200] loss: 0.013\n",
      "[83,   300] loss: 0.015\n",
      "[83,   400] loss: 0.015\n",
      "[83,   500] loss: 0.015\n",
      "[83,   600] loss: 0.021\n",
      "[83,   700] loss: 0.019\n",
      "[84,   100] loss: 0.011\n",
      "[84,   200] loss: 0.016\n",
      "[84,   300] loss: 0.026\n",
      "[84,   400] loss: 0.038\n",
      "[84,   500] loss: 0.037\n",
      "[84,   600] loss: 0.031\n",
      "[84,   700] loss: 0.025\n",
      "[85,   100] loss: 0.019\n",
      "[85,   200] loss: 0.013\n",
      "[85,   300] loss: 0.017\n",
      "[85,   400] loss: 0.012\n",
      "[85,   500] loss: 0.014\n",
      "[85,   600] loss: 0.026\n",
      "[85,   700] loss: 0.022\n",
      "[86,   100] loss: 0.033\n",
      "[86,   200] loss: 0.023\n",
      "[86,   300] loss: 0.023\n",
      "[86,   400] loss: 0.018\n",
      "[86,   500] loss: 0.019\n",
      "[86,   600] loss: 0.020\n",
      "[86,   700] loss: 0.018\n",
      "[87,   100] loss: 0.016\n",
      "[87,   200] loss: 0.015\n",
      "[87,   300] loss: 0.014\n",
      "[87,   400] loss: 0.020\n",
      "[87,   500] loss: 0.016\n",
      "[87,   600] loss: 0.026\n",
      "[87,   700] loss: 0.029\n",
      "[88,   100] loss: 0.020\n",
      "[88,   200] loss: 0.018\n",
      "[88,   300] loss: 0.009\n",
      "[88,   400] loss: 0.016\n",
      "[88,   500] loss: 0.019\n",
      "[88,   600] loss: 0.025\n",
      "[88,   700] loss: 0.031\n",
      "[89,   100] loss: 0.022\n",
      "[89,   200] loss: 0.026\n",
      "[89,   300] loss: 0.025\n",
      "[89,   400] loss: 0.021\n",
      "[89,   500] loss: 0.021\n",
      "[89,   600] loss: 0.015\n",
      "[89,   700] loss: 0.015\n",
      "[90,   100] loss: 0.030\n",
      "[90,   200] loss: 0.023\n",
      "[90,   300] loss: 0.031\n",
      "[90,   400] loss: 0.025\n",
      "[90,   500] loss: 0.017\n",
      "[90,   600] loss: 0.027\n",
      "[90,   700] loss: 0.020\n",
      "[91,   100] loss: 0.040\n",
      "[91,   200] loss: 0.034\n",
      "[91,   300] loss: 0.026\n",
      "[91,   400] loss: 0.021\n",
      "[91,   500] loss: 0.016\n",
      "[91,   600] loss: 0.014\n",
      "[91,   700] loss: 0.023\n",
      "[92,   100] loss: 0.013\n",
      "[92,   200] loss: 0.012\n",
      "[92,   300] loss: 0.009\n",
      "[92,   400] loss: 0.021\n",
      "[92,   500] loss: 0.017\n",
      "[92,   600] loss: 0.016\n",
      "[92,   700] loss: 0.017\n",
      "[93,   100] loss: 0.029\n",
      "[93,   200] loss: 0.016\n",
      "[93,   300] loss: 0.018\n",
      "[93,   400] loss: 0.015\n",
      "[93,   500] loss: 0.022\n",
      "[93,   600] loss: 0.020\n",
      "[93,   700] loss: 0.016\n",
      "[94,   100] loss: 0.017\n",
      "[94,   200] loss: 0.021\n",
      "[94,   300] loss: 0.019\n",
      "[94,   400] loss: 0.023\n",
      "[94,   500] loss: 0.022\n",
      "[94,   600] loss: 0.021\n",
      "[94,   700] loss: 0.029\n",
      "[95,   100] loss: 0.022\n",
      "[95,   200] loss: 0.018\n",
      "[95,   300] loss: 0.020\n",
      "[95,   400] loss: 0.011\n",
      "[95,   500] loss: 0.016\n",
      "[95,   600] loss: 0.024\n",
      "[95,   700] loss: 0.030\n",
      "[96,   100] loss: 0.020\n",
      "[96,   200] loss: 0.014\n",
      "[96,   300] loss: 0.011\n",
      "[96,   400] loss: 0.009\n",
      "[96,   500] loss: 0.020\n",
      "[96,   600] loss: 0.015\n",
      "[96,   700] loss: 0.016\n",
      "[97,   100] loss: 0.010\n",
      "[97,   200] loss: 0.018\n",
      "[97,   300] loss: 0.013\n",
      "[97,   400] loss: 0.017\n",
      "[97,   500] loss: 0.016\n",
      "[97,   600] loss: 0.019\n",
      "[97,   700] loss: 0.016\n",
      "[98,   100] loss: 0.014\n",
      "[98,   200] loss: 0.015\n",
      "[98,   300] loss: 0.008\n",
      "[98,   400] loss: 0.016\n",
      "[98,   500] loss: 0.013\n",
      "[98,   600] loss: 0.016\n",
      "[98,   700] loss: 0.017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99,   100] loss: 0.008\n",
      "[99,   200] loss: 0.012\n",
      "[99,   300] loss: 0.012\n",
      "[99,   400] loss: 0.012\n",
      "[99,   500] loss: 0.022\n",
      "[99,   600] loss: 0.016\n",
      "[99,   700] loss: 0.009\n",
      "[100,   100] loss: 0.020\n",
      "[100,   200] loss: 0.012\n",
      "[100,   300] loss: 0.018\n",
      "[100,   400] loss: 0.017\n",
      "[100,   500] loss: 0.015\n",
      "[100,   600] loss: 0.023\n",
      "[100,   700] loss: 0.029\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs) \n",
    "        loss =  criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T06:59:07.751679Z",
     "start_time": "2020-10-08T06:58:38.171245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 79.900000 %\n",
      "Accuracy of   car : 89.500000 %\n",
      "Accuracy of  bird : 75.400000 %\n",
      "Accuracy of   cat : 56.500000 %\n",
      "Accuracy of  deer : 71.900000 %\n",
      "Accuracy of   dog : 59.800000 %\n",
      "Accuracy of  frog : 80.100000 %\n",
      "Accuracy of horse : 81.200000 %\n",
      "Accuracy of  ship : 88.200000 %\n",
      "Accuracy of truck : 71.900000 %\n",
      "Mean Accuracy :  75.44\n"
     ]
    }
   ],
   "source": [
    "class_correct = np.zeros(10)\n",
    "class_total = np.zeros(10)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print('Mean Accuracy : ', 100*np.sum(class_correct)/np.sum(class_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
