{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Challange - 김영인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. wide resnet\n",
    "2. \\+ Data Augmentation(RandomResizedCrop, RandomHorizontalFlip)\n",
    "3. \\+ Data Normalize\n",
    "4. \\+ regularization(dropout, weight decay)\n",
    "5. \\+ Optimizer(momentum, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T13:01:13.213127Z",
     "start_time": "2020-10-07T13:01:13.198192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "random_seed = 4332\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device1 = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = device0\n",
    "print(f\"device: {device}\") if torch.cuda.is_available() else print(\"device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T13:03:13.850983Z",
     "start_time": "2020-10-07T13:03:13.844262Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "scheduler_step = 60\n",
    "scheduler_gamma = 0.2\n",
    "training_epochs = 200\n",
    "batch_size = 64\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T13:01:23.424380Z",
     "start_time": "2020-10-07T13:01:21.814233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(224), # data augmentation, 224: image size, ImageNet pretrained model에 맞추기 위해서 224 size로 설정\n",
    "     transforms.RandomHorizontalFlip(), # data augmentation, 좌우로 대칭\n",
    "     transforms.ToTensor(), # numpy array를 pytorch tensor로 바꿔주는 역할\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # dataset의 mean, std를 이용해서 -1~1 로 normalize\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "testloader = DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Define pretrained model and fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T12:56:46.918001Z",
     "start_time": "2020-10-07T12:56:45.612688Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(models.wide_resnet50_2(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T13:03:41.316897Z",
     "start_time": "2020-10-07T13:03:41.309554Z"
    }
   },
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(WideResNet, self).__init__()\n",
    "        self.resnet = models.wide_resnet50_2(pretrained=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1000, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T13:03:43.058559Z",
     "start_time": "2020-10-07T13:03:41.738234Z"
    }
   },
   "outputs": [],
   "source": [
    "net = WideResNet()\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-07T16:59:08.859429Z",
     "start_time": "2020-10-07T13:03:44.166337Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.445\n",
      "[1,   200] loss: 2.068\n",
      "[1,   300] loss: 1.913\n",
      "[1,   400] loss: 1.889\n",
      "[1,   500] loss: 1.854\n",
      "[1,   600] loss: 1.793\n",
      "[1,   700] loss: 1.717\n",
      "[2,   100] loss: 1.620\n",
      "[2,   200] loss: 1.637\n",
      "[2,   300] loss: 1.610\n",
      "[2,   400] loss: 1.540\n",
      "[2,   500] loss: 1.532\n",
      "[2,   600] loss: 1.509\n",
      "[2,   700] loss: 1.487\n",
      "[3,   100] loss: 1.433\n",
      "[3,   200] loss: 1.409\n",
      "[3,   300] loss: 1.380\n",
      "[3,   400] loss: 1.387\n",
      "[3,   500] loss: 1.365\n",
      "[3,   600] loss: 1.329\n",
      "[3,   700] loss: 1.301\n",
      "[4,   100] loss: 1.281\n",
      "[4,   200] loss: 1.295\n",
      "[4,   300] loss: 1.252\n",
      "[4,   400] loss: 1.230\n",
      "[4,   500] loss: 1.246\n",
      "[4,   600] loss: 1.240\n",
      "[4,   700] loss: 1.224\n",
      "[5,   100] loss: 1.153\n",
      "[5,   200] loss: 1.158\n",
      "[5,   300] loss: 1.183\n",
      "[5,   400] loss: 1.130\n",
      "[5,   500] loss: 1.132\n",
      "[5,   600] loss: 1.155\n",
      "[5,   700] loss: 1.153\n",
      "[6,   100] loss: 1.077\n",
      "[6,   200] loss: 1.098\n",
      "[6,   300] loss: 1.093\n",
      "[6,   400] loss: 1.123\n",
      "[6,   500] loss: 1.113\n",
      "[6,   600] loss: 1.081\n",
      "[6,   700] loss: 1.064\n",
      "[7,   100] loss: 1.051\n",
      "[7,   200] loss: 1.069\n",
      "[7,   300] loss: 1.072\n",
      "[7,   400] loss: 1.077\n",
      "[7,   500] loss: 1.063\n",
      "[7,   600] loss: 1.020\n",
      "[7,   700] loss: 1.049\n",
      "[8,   100] loss: 1.023\n",
      "[8,   200] loss: 1.018\n",
      "[8,   300] loss: 1.004\n",
      "[8,   400] loss: 1.038\n",
      "[8,   500] loss: 1.030\n",
      "[8,   600] loss: 1.031\n",
      "[8,   700] loss: 1.005\n",
      "[9,   100] loss: 0.992\n",
      "[9,   200] loss: 0.975\n",
      "[9,   300] loss: 1.000\n",
      "[9,   400] loss: 0.996\n",
      "[9,   500] loss: 1.020\n",
      "[9,   600] loss: 1.014\n",
      "[9,   700] loss: 1.008\n",
      "[10,   100] loss: 0.988\n",
      "[10,   200] loss: 0.961\n",
      "[10,   300] loss: 1.002\n",
      "[10,   400] loss: 0.960\n",
      "[10,   500] loss: 0.974\n",
      "[10,   600] loss: 0.989\n",
      "[10,   700] loss: 0.957\n",
      "[11,   100] loss: 0.934\n",
      "[11,   200] loss: 0.972\n",
      "[11,   300] loss: 0.966\n",
      "[11,   400] loss: 0.943\n",
      "[11,   500] loss: 0.959\n",
      "[11,   600] loss: 0.981\n",
      "[11,   700] loss: 0.945\n",
      "[12,   100] loss: 0.983\n",
      "[12,   200] loss: 0.892\n",
      "[12,   300] loss: 0.946\n",
      "[12,   400] loss: 0.939\n",
      "[12,   500] loss: 0.916\n",
      "[12,   600] loss: 0.960\n",
      "[12,   700] loss: 0.989\n",
      "[13,   100] loss: 0.939\n",
      "[13,   200] loss: 0.939\n",
      "[13,   300] loss: 0.880\n",
      "[13,   400] loss: 0.946\n",
      "[13,   500] loss: 0.943\n",
      "[13,   600] loss: 0.961\n",
      "[13,   700] loss: 0.936\n",
      "[14,   100] loss: 0.892\n",
      "[14,   200] loss: 0.921\n",
      "[14,   300] loss: 0.926\n",
      "[14,   400] loss: 0.947\n",
      "[14,   500] loss: 0.923\n",
      "[14,   600] loss: 0.943\n",
      "[14,   700] loss: 0.952\n",
      "[15,   100] loss: 0.898\n",
      "[15,   200] loss: 0.863\n",
      "[15,   300] loss: 0.935\n",
      "[15,   400] loss: 0.934\n",
      "[15,   500] loss: 0.926\n",
      "[15,   600] loss: 0.913\n",
      "[15,   700] loss: 0.931\n",
      "[16,   100] loss: 0.861\n",
      "[16,   200] loss: 0.882\n",
      "[16,   300] loss: 0.903\n",
      "[16,   400] loss: 0.915\n",
      "[16,   500] loss: 0.924\n",
      "[16,   600] loss: 0.906\n",
      "[16,   700] loss: 0.928\n",
      "[17,   100] loss: 0.862\n",
      "[17,   200] loss: 0.889\n",
      "[17,   300] loss: 0.935\n",
      "[17,   400] loss: 0.911\n",
      "[17,   500] loss: 0.897\n",
      "[17,   600] loss: 0.910\n",
      "[17,   700] loss: 0.890\n",
      "[18,   100] loss: 0.841\n",
      "[18,   200] loss: 0.884\n",
      "[18,   300] loss: 0.908\n",
      "[18,   400] loss: 0.883\n",
      "[18,   500] loss: 0.908\n",
      "[18,   600] loss: 0.915\n",
      "[18,   700] loss: 0.923\n",
      "[19,   100] loss: 0.862\n",
      "[19,   200] loss: 0.906\n",
      "[19,   300] loss: 0.858\n",
      "[19,   400] loss: 0.868\n",
      "[19,   500] loss: 0.916\n",
      "[19,   600] loss: 0.898\n",
      "[19,   700] loss: 0.915\n",
      "[20,   100] loss: 0.862\n",
      "[20,   200] loss: 0.885\n",
      "[20,   300] loss: 0.849\n",
      "[20,   400] loss: 0.887\n",
      "[20,   500] loss: 0.880\n",
      "[20,   600] loss: 0.878\n",
      "[20,   700] loss: 0.880\n",
      "[21,   100] loss: 0.857\n",
      "[21,   200] loss: 0.857\n",
      "[21,   300] loss: 0.891\n",
      "[21,   400] loss: 0.904\n",
      "[21,   500] loss: 0.908\n",
      "[21,   600] loss: 0.896\n",
      "[21,   700] loss: 0.873\n",
      "[22,   100] loss: 0.862\n",
      "[22,   200] loss: 0.859\n",
      "[22,   300] loss: 0.858\n",
      "[22,   400] loss: 0.873\n",
      "[22,   500] loss: 0.867\n",
      "[22,   600] loss: 0.884\n",
      "[22,   700] loss: 0.871\n",
      "[23,   100] loss: 0.857\n",
      "[23,   200] loss: 0.871\n",
      "[23,   300] loss: 0.882\n",
      "[23,   400] loss: 0.858\n",
      "[23,   500] loss: 0.880\n",
      "[23,   600] loss: 0.861\n",
      "[23,   700] loss: 0.881\n",
      "[24,   100] loss: 0.813\n",
      "[24,   200] loss: 0.855\n",
      "[24,   300] loss: 0.869\n",
      "[24,   400] loss: 0.867\n",
      "[24,   500] loss: 0.857\n",
      "[24,   600] loss: 0.851\n",
      "[24,   700] loss: 0.909\n",
      "[25,   100] loss: 0.847\n",
      "[25,   200] loss: 0.865\n",
      "[25,   300] loss: 0.820\n",
      "[25,   400] loss: 0.852\n",
      "[25,   500] loss: 0.871\n",
      "[25,   600] loss: 0.862\n",
      "[25,   700] loss: 0.856\n",
      "[26,   100] loss: 0.823\n",
      "[26,   200] loss: 0.859\n",
      "[26,   300] loss: 0.840\n",
      "[26,   400] loss: 0.871\n",
      "[26,   500] loss: 0.836\n",
      "[26,   600] loss: 0.869\n",
      "[26,   700] loss: 0.863\n",
      "[27,   100] loss: 0.836\n",
      "[27,   200] loss: 0.836\n",
      "[27,   300] loss: 0.873\n",
      "[27,   400] loss: 0.861\n",
      "[27,   500] loss: 0.864\n",
      "[27,   600] loss: 0.837\n",
      "[27,   700] loss: 0.893\n",
      "[28,   100] loss: 0.795\n",
      "[28,   200] loss: 0.828\n",
      "[28,   300] loss: 0.825\n",
      "[28,   400] loss: 0.851\n",
      "[28,   500] loss: 0.867\n",
      "[28,   600] loss: 0.885\n",
      "[28,   700] loss: 0.871\n",
      "[29,   100] loss: 0.882\n",
      "[29,   200] loss: 0.856\n",
      "[29,   300] loss: 0.839\n",
      "[29,   400] loss: 0.839\n",
      "[29,   500] loss: 0.821\n",
      "[29,   600] loss: 0.858\n",
      "[29,   700] loss: 0.856\n",
      "[30,   100] loss: 0.791\n",
      "[30,   200] loss: 0.828\n",
      "[30,   300] loss: 0.835\n",
      "[30,   400] loss: 0.841\n",
      "[30,   500] loss: 0.834\n",
      "[30,   600] loss: 0.886\n",
      "[30,   700] loss: 0.845\n",
      "[31,   100] loss: 0.843\n",
      "[31,   200] loss: 0.821\n",
      "[31,   300] loss: 0.845\n",
      "[31,   400] loss: 0.848\n",
      "[31,   500] loss: 0.846\n",
      "[31,   600] loss: 0.866\n",
      "[31,   700] loss: 0.840\n",
      "[32,   100] loss: 0.806\n",
      "[32,   200] loss: 0.803\n",
      "[32,   300] loss: 0.833\n",
      "[32,   400] loss: 0.842\n",
      "[32,   500] loss: 0.836\n",
      "[32,   600] loss: 0.870\n",
      "[32,   700] loss: 0.874\n",
      "[33,   100] loss: 0.847\n",
      "[33,   200] loss: 0.815\n",
      "[33,   300] loss: 0.839\n",
      "[33,   400] loss: 0.848\n",
      "[33,   500] loss: 0.836\n",
      "[33,   600] loss: 0.836\n",
      "[33,   700] loss: 0.856\n",
      "[34,   100] loss: 0.797\n",
      "[34,   200] loss: 0.837\n",
      "[34,   300] loss: 0.825\n",
      "[34,   400] loss: 0.835\n",
      "[34,   500] loss: 0.843\n",
      "[34,   600] loss: 0.826\n",
      "[34,   700] loss: 0.861\n",
      "[35,   100] loss: 0.809\n",
      "[35,   200] loss: 0.808\n",
      "[35,   300] loss: 0.842\n",
      "[35,   400] loss: 0.846\n",
      "[35,   500] loss: 0.832\n",
      "[35,   600] loss: 0.848\n",
      "[35,   700] loss: 0.823\n",
      "[36,   100] loss: 0.805\n",
      "[36,   200] loss: 0.840\n",
      "[36,   300] loss: 0.840\n",
      "[36,   400] loss: 0.824\n",
      "[36,   500] loss: 0.864\n",
      "[36,   600] loss: 0.815\n",
      "[36,   700] loss: 0.855\n",
      "[37,   100] loss: 0.827\n",
      "[37,   200] loss: 0.823\n",
      "[37,   300] loss: 0.832\n",
      "[37,   400] loss: 0.802\n",
      "[37,   500] loss: 0.864\n",
      "[37,   600] loss: 0.811\n",
      "[37,   700] loss: 0.863\n",
      "[38,   100] loss: 0.766\n",
      "[38,   200] loss: 0.801\n",
      "[38,   300] loss: 0.857\n",
      "[38,   400] loss: 0.844\n",
      "[38,   500] loss: 0.817\n",
      "[38,   600] loss: 0.825\n",
      "[38,   700] loss: 0.870\n",
      "[39,   100] loss: 0.848\n",
      "[39,   200] loss: 0.812\n",
      "[39,   300] loss: 0.831\n",
      "[39,   400] loss: 0.821\n",
      "[39,   500] loss: 0.837\n",
      "[39,   600] loss: 0.851\n",
      "[39,   700] loss: 0.845\n",
      "[40,   100] loss: 0.796\n",
      "[40,   200] loss: 0.817\n",
      "[40,   300] loss: 0.807\n",
      "[40,   400] loss: 0.843\n",
      "[40,   500] loss: 0.847\n",
      "[40,   600] loss: 0.845\n",
      "[40,   700] loss: 0.847\n",
      "[41,   100] loss: 0.802\n",
      "[41,   200] loss: 0.811\n",
      "[41,   300] loss: 0.825\n",
      "[41,   400] loss: 0.832\n",
      "[41,   500] loss: 0.853\n",
      "[41,   600] loss: 0.833\n",
      "[41,   700] loss: 0.855\n",
      "[42,   100] loss: 0.796\n",
      "[42,   200] loss: 0.823\n",
      "[42,   300] loss: 0.833\n",
      "[42,   400] loss: 0.820\n",
      "[42,   500] loss: 0.827\n",
      "[42,   600] loss: 0.839\n",
      "[42,   700] loss: 0.858\n",
      "[43,   100] loss: 0.801\n",
      "[43,   200] loss: 0.822\n",
      "[43,   300] loss: 0.812\n",
      "[43,   400] loss: 0.828\n",
      "[43,   500] loss: 0.838\n",
      "[43,   600] loss: 0.844\n",
      "[43,   700] loss: 0.818\n",
      "[44,   100] loss: 0.828\n",
      "[44,   200] loss: 0.799\n",
      "[44,   300] loss: 0.801\n",
      "[44,   400] loss: 0.846\n",
      "[44,   500] loss: 0.841\n",
      "[44,   600] loss: 0.838\n",
      "[44,   700] loss: 0.808\n",
      "[45,   100] loss: 0.797\n",
      "[45,   200] loss: 0.794\n",
      "[45,   300] loss: 0.794\n",
      "[45,   400] loss: 0.810\n",
      "[45,   500] loss: 0.839\n",
      "[45,   600] loss: 0.861\n",
      "[45,   700] loss: 0.856\n",
      "[46,   100] loss: 0.795\n",
      "[46,   200] loss: 0.798\n",
      "[46,   300] loss: 0.814\n",
      "[46,   400] loss: 0.804\n",
      "[46,   500] loss: 0.840\n",
      "[46,   600] loss: 0.813\n",
      "[46,   700] loss: 0.808\n",
      "[47,   100] loss: 0.818\n",
      "[47,   200] loss: 0.801\n",
      "[47,   300] loss: 0.812\n",
      "[47,   400] loss: 0.822\n",
      "[47,   500] loss: 0.818\n",
      "[47,   600] loss: 0.823\n",
      "[47,   700] loss: 0.836\n",
      "[48,   100] loss: 0.823\n",
      "[48,   200] loss: 0.791\n",
      "[48,   300] loss: 0.795\n",
      "[48,   400] loss: 0.846\n",
      "[48,   500] loss: 0.844\n",
      "[48,   600] loss: 0.828\n",
      "[48,   700] loss: 0.818\n",
      "[49,   100] loss: 0.787\n",
      "[49,   200] loss: 0.755\n",
      "[49,   300] loss: 0.827\n",
      "[49,   400] loss: 0.820\n",
      "[49,   500] loss: 0.833\n",
      "[49,   600] loss: 0.834\n",
      "[49,   700] loss: 0.869\n",
      "[50,   100] loss: 0.786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50,   200] loss: 0.780\n",
      "[50,   300] loss: 0.818\n",
      "[50,   400] loss: 0.823\n",
      "[50,   500] loss: 0.824\n",
      "[50,   600] loss: 0.805\n",
      "[50,   700] loss: 0.862\n",
      "[51,   100] loss: 0.780\n",
      "[51,   200] loss: 0.795\n",
      "[51,   300] loss: 0.838\n",
      "[51,   400] loss: 0.821\n",
      "[51,   500] loss: 0.843\n",
      "[51,   600] loss: 0.840\n",
      "[51,   700] loss: 0.849\n",
      "[52,   100] loss: 0.787\n",
      "[52,   200] loss: 0.782\n",
      "[52,   300] loss: 0.799\n",
      "[52,   400] loss: 0.821\n",
      "[52,   500] loss: 0.789\n",
      "[52,   600] loss: 0.827\n",
      "[52,   700] loss: 0.854\n",
      "[53,   100] loss: 0.744\n",
      "[53,   200] loss: 0.789\n",
      "[53,   300] loss: 0.805\n",
      "[53,   400] loss: 0.807\n",
      "[53,   500] loss: 0.838\n",
      "[53,   600] loss: 0.866\n",
      "[53,   700] loss: 0.833\n",
      "[54,   100] loss: 0.760\n",
      "[54,   200] loss: 0.769\n",
      "[54,   300] loss: 0.808\n",
      "[54,   400] loss: 0.824\n",
      "[54,   500] loss: 0.820\n",
      "[54,   600] loss: 0.818\n",
      "[54,   700] loss: 0.864\n",
      "[55,   100] loss: 0.764\n",
      "[55,   200] loss: 0.800\n",
      "[55,   300] loss: 0.780\n",
      "[55,   400] loss: 0.800\n",
      "[55,   500] loss: 0.847\n",
      "[55,   600] loss: 0.826\n",
      "[55,   700] loss: 0.815\n",
      "[56,   100] loss: 0.788\n",
      "[56,   200] loss: 0.780\n",
      "[56,   300] loss: 0.794\n",
      "[56,   400] loss: 0.818\n",
      "[56,   500] loss: 0.796\n",
      "[56,   600] loss: 0.828\n",
      "[56,   700] loss: 0.845\n",
      "[57,   100] loss: 0.795\n",
      "[57,   200] loss: 0.790\n",
      "[57,   300] loss: 0.791\n",
      "[57,   400] loss: 0.825\n",
      "[57,   500] loss: 0.835\n",
      "[57,   600] loss: 0.829\n",
      "[57,   700] loss: 0.835\n",
      "[58,   100] loss: 0.788\n",
      "[58,   200] loss: 0.787\n",
      "[58,   300] loss: 0.773\n",
      "[58,   400] loss: 0.808\n",
      "[58,   500] loss: 0.829\n",
      "[58,   600] loss: 0.823\n",
      "[58,   700] loss: 0.840\n",
      "[59,   100] loss: 0.794\n",
      "[59,   200] loss: 0.797\n",
      "[59,   300] loss: 0.796\n",
      "[59,   400] loss: 0.825\n",
      "[59,   500] loss: 0.789\n",
      "[59,   600] loss: 0.834\n",
      "[59,   700] loss: 0.825\n",
      "[60,   100] loss: 0.776\n",
      "[60,   200] loss: 0.779\n",
      "[60,   300] loss: 0.814\n",
      "[60,   400] loss: 0.814\n",
      "[60,   500] loss: 0.838\n",
      "[60,   600] loss: 0.816\n",
      "[60,   700] loss: 0.847\n",
      "[61,   100] loss: 0.771\n",
      "[61,   200] loss: 0.825\n",
      "[61,   300] loss: 0.810\n",
      "[61,   400] loss: 0.806\n",
      "[61,   500] loss: 0.831\n",
      "[61,   600] loss: 0.809\n",
      "[61,   700] loss: 0.832\n",
      "[62,   100] loss: 0.796\n",
      "[62,   200] loss: 0.792\n",
      "[62,   300] loss: 0.803\n",
      "[62,   400] loss: 0.803\n",
      "[62,   500] loss: 0.830\n",
      "[62,   600] loss: 0.817\n",
      "[62,   700] loss: 0.788\n",
      "[63,   100] loss: 0.762\n",
      "[63,   200] loss: 0.802\n",
      "[63,   300] loss: 0.808\n",
      "[63,   400] loss: 0.816\n",
      "[63,   500] loss: 0.828\n",
      "[63,   600] loss: 0.824\n",
      "[63,   700] loss: 0.813\n",
      "[64,   100] loss: 0.766\n",
      "[64,   200] loss: 0.778\n",
      "[64,   300] loss: 0.814\n",
      "[64,   400] loss: 0.771\n",
      "[64,   500] loss: 0.803\n",
      "[64,   600] loss: 0.815\n",
      "[64,   700] loss: 0.821\n",
      "[65,   100] loss: 0.787\n",
      "[65,   200] loss: 0.811\n",
      "[65,   300] loss: 0.809\n",
      "[65,   400] loss: 0.798\n",
      "[65,   500] loss: 0.809\n",
      "[65,   600] loss: 0.818\n",
      "[65,   700] loss: 0.833\n",
      "[66,   100] loss: 0.769\n",
      "[66,   200] loss: 0.778\n",
      "[66,   300] loss: 0.808\n",
      "[66,   400] loss: 0.837\n",
      "[66,   500] loss: 0.809\n",
      "[66,   600] loss: 0.801\n",
      "[66,   700] loss: 0.819\n",
      "[67,   100] loss: 0.789\n",
      "[67,   200] loss: 0.816\n",
      "[67,   300] loss: 0.789\n",
      "[67,   400] loss: 0.800\n",
      "[67,   500] loss: 0.804\n",
      "[67,   600] loss: 0.813\n",
      "[67,   700] loss: 0.829\n",
      "[68,   100] loss: 0.752\n",
      "[68,   200] loss: 0.792\n",
      "[68,   300] loss: 0.802\n",
      "[68,   400] loss: 0.800\n",
      "[68,   500] loss: 0.821\n",
      "[68,   600] loss: 0.825\n",
      "[68,   700] loss: 0.837\n",
      "[69,   100] loss: 0.787\n",
      "[69,   200] loss: 0.791\n",
      "[69,   300] loss: 0.809\n",
      "[69,   400] loss: 0.829\n",
      "[69,   500] loss: 0.835\n",
      "[69,   600] loss: 0.804\n",
      "[69,   700] loss: 0.837\n",
      "[70,   100] loss: 0.781\n",
      "[70,   200] loss: 0.767\n",
      "[70,   300] loss: 0.771\n",
      "[70,   400] loss: 0.822\n",
      "[70,   500] loss: 0.815\n",
      "[70,   600] loss: 0.820\n",
      "[70,   700] loss: 0.829\n",
      "[71,   100] loss: 0.779\n",
      "[71,   200] loss: 0.784\n",
      "[71,   300] loss: 0.818\n",
      "[71,   400] loss: 0.783\n",
      "[71,   500] loss: 0.801\n",
      "[71,   600] loss: 0.813\n",
      "[71,   700] loss: 0.818\n",
      "[72,   100] loss: 0.780\n",
      "[72,   200] loss: 0.779\n",
      "[72,   300] loss: 0.793\n",
      "[72,   400] loss: 0.830\n",
      "[72,   500] loss: 0.793\n",
      "[72,   600] loss: 0.781\n",
      "[72,   700] loss: 0.860\n",
      "[73,   100] loss: 0.768\n",
      "[73,   200] loss: 0.796\n",
      "[73,   300] loss: 0.797\n",
      "[73,   400] loss: 0.793\n",
      "[73,   500] loss: 0.796\n",
      "[73,   600] loss: 0.798\n",
      "[73,   700] loss: 0.838\n",
      "[74,   100] loss: 0.789\n",
      "[74,   200] loss: 0.769\n",
      "[74,   300] loss: 0.779\n",
      "[74,   400] loss: 0.800\n",
      "[74,   500] loss: 0.807\n",
      "[74,   600] loss: 0.824\n",
      "[74,   700] loss: 0.839\n",
      "[75,   100] loss: 0.761\n",
      "[75,   200] loss: 0.769\n",
      "[75,   300] loss: 0.776\n",
      "[75,   400] loss: 0.814\n",
      "[75,   500] loss: 0.822\n",
      "[75,   600] loss: 0.796\n",
      "[75,   700] loss: 0.818\n",
      "[76,   100] loss: 0.756\n",
      "[76,   200] loss: 0.788\n",
      "[76,   300] loss: 0.779\n",
      "[76,   400] loss: 0.794\n",
      "[76,   500] loss: 0.830\n",
      "[76,   600] loss: 0.837\n",
      "[76,   700] loss: 0.815\n",
      "[77,   100] loss: 0.759\n",
      "[77,   200] loss: 0.789\n",
      "[77,   300] loss: 0.821\n",
      "[77,   400] loss: 0.784\n",
      "[77,   500] loss: 0.798\n",
      "[77,   600] loss: 0.807\n",
      "[77,   700] loss: 0.833\n",
      "[78,   100] loss: 0.815\n",
      "[78,   200] loss: 0.782\n",
      "[78,   300] loss: 0.783\n",
      "[78,   400] loss: 0.795\n",
      "[78,   500] loss: 0.840\n",
      "[78,   600] loss: 0.801\n",
      "[78,   700] loss: 0.821\n",
      "[79,   100] loss: 0.751\n",
      "[79,   200] loss: 0.784\n",
      "[79,   300] loss: 0.795\n",
      "[79,   400] loss: 0.798\n",
      "[79,   500] loss: 0.805\n",
      "[79,   600] loss: 0.785\n",
      "[79,   700] loss: 0.821\n",
      "[80,   100] loss: 0.752\n",
      "[80,   200] loss: 0.805\n",
      "[80,   300] loss: 0.816\n",
      "[80,   400] loss: 0.780\n",
      "[80,   500] loss: 0.782\n",
      "[80,   600] loss: 0.834\n",
      "[80,   700] loss: 0.802\n",
      "[81,   100] loss: 0.751\n",
      "[81,   200] loss: 0.803\n",
      "[81,   300] loss: 0.770\n",
      "[81,   400] loss: 0.822\n",
      "[81,   500] loss: 0.794\n",
      "[81,   600] loss: 0.806\n",
      "[81,   700] loss: 0.802\n",
      "[82,   100] loss: 0.774\n",
      "[82,   200] loss: 0.785\n",
      "[82,   300] loss: 0.787\n",
      "[82,   400] loss: 0.795\n",
      "[82,   500] loss: 0.819\n",
      "[82,   600] loss: 0.830\n",
      "[82,   700] loss: 0.783\n",
      "[83,   100] loss: 0.765\n",
      "[83,   200] loss: 0.764\n",
      "[83,   300] loss: 0.773\n",
      "[83,   400] loss: 0.815\n",
      "[83,   500] loss: 0.797\n",
      "[83,   600] loss: 0.804\n",
      "[83,   700] loss: 0.816\n",
      "[84,   100] loss: 0.751\n",
      "[84,   200] loss: 0.793\n",
      "[84,   300] loss: 0.823\n",
      "[84,   400] loss: 0.792\n",
      "[84,   500] loss: 0.796\n",
      "[84,   600] loss: 0.761\n",
      "[84,   700] loss: 0.805\n",
      "[85,   100] loss: 0.767\n",
      "[85,   200] loss: 0.761\n",
      "[85,   300] loss: 0.795\n",
      "[85,   400] loss: 0.776\n",
      "[85,   500] loss: 0.818\n",
      "[85,   600] loss: 0.810\n",
      "[85,   700] loss: 0.798\n",
      "[86,   100] loss: 0.779\n",
      "[86,   200] loss: 0.787\n",
      "[86,   300] loss: 0.794\n",
      "[86,   400] loss: 0.805\n",
      "[86,   500] loss: 0.800\n",
      "[86,   600] loss: 0.800\n",
      "[86,   700] loss: 0.803\n",
      "[87,   100] loss: 0.761\n",
      "[87,   200] loss: 0.765\n",
      "[87,   300] loss: 0.773\n",
      "[87,   400] loss: 0.805\n",
      "[87,   500] loss: 0.765\n",
      "[87,   600] loss: 0.846\n",
      "[87,   700] loss: 0.807\n",
      "[88,   100] loss: 0.764\n",
      "[88,   200] loss: 0.785\n",
      "[88,   300] loss: 0.765\n",
      "[88,   400] loss: 0.772\n",
      "[88,   500] loss: 0.816\n",
      "[88,   600] loss: 0.794\n",
      "[88,   700] loss: 0.821\n",
      "[89,   100] loss: 0.754\n",
      "[89,   200] loss: 0.771\n",
      "[89,   300] loss: 0.771\n",
      "[89,   400] loss: 0.818\n",
      "[89,   500] loss: 0.808\n",
      "[89,   600] loss: 0.831\n",
      "[89,   700] loss: 0.790\n",
      "[90,   100] loss: 0.771\n",
      "[90,   200] loss: 0.780\n",
      "[90,   300] loss: 0.792\n",
      "[90,   400] loss: 0.776\n",
      "[90,   500] loss: 0.802\n",
      "[90,   600] loss: 0.836\n",
      "[90,   700] loss: 0.810\n",
      "[91,   100] loss: 0.772\n",
      "[91,   200] loss: 0.792\n",
      "[91,   300] loss: 0.816\n",
      "[91,   400] loss: 0.781\n",
      "[91,   500] loss: 0.793\n",
      "[91,   600] loss: 0.815\n",
      "[91,   700] loss: 0.817\n",
      "[92,   100] loss: 0.769\n",
      "[92,   200] loss: 0.787\n",
      "[92,   300] loss: 0.774\n",
      "[92,   400] loss: 0.791\n",
      "[92,   500] loss: 0.812\n",
      "[92,   600] loss: 0.811\n",
      "[92,   700] loss: 0.795\n",
      "[93,   100] loss: 0.742\n",
      "[93,   200] loss: 0.782\n",
      "[93,   300] loss: 0.789\n",
      "[93,   400] loss: 0.766\n",
      "[93,   500] loss: 0.774\n",
      "[93,   600] loss: 0.808\n",
      "[93,   700] loss: 0.813\n",
      "[94,   100] loss: 0.751\n",
      "[94,   200] loss: 0.767\n",
      "[94,   300] loss: 0.774\n",
      "[94,   400] loss: 0.781\n",
      "[94,   500] loss: 0.798\n",
      "[94,   600] loss: 0.834\n",
      "[94,   700] loss: 0.808\n",
      "[95,   100] loss: 0.800\n",
      "[95,   200] loss: 0.758\n",
      "[95,   300] loss: 0.777\n",
      "[95,   400] loss: 0.794\n",
      "[95,   500] loss: 0.814\n",
      "[95,   600] loss: 0.798\n",
      "[95,   700] loss: 0.835\n",
      "[96,   100] loss: 0.753\n",
      "[96,   200] loss: 0.740\n",
      "[96,   300] loss: 0.811\n",
      "[96,   400] loss: 0.778\n",
      "[96,   500] loss: 0.803\n",
      "[96,   600] loss: 0.807\n",
      "[96,   700] loss: 0.810\n",
      "[97,   100] loss: 0.755\n",
      "[97,   200] loss: 0.776\n",
      "[97,   300] loss: 0.807\n",
      "[97,   400] loss: 0.797\n",
      "[97,   500] loss: 0.800\n",
      "[97,   600] loss: 0.802\n",
      "[97,   700] loss: 0.839\n",
      "[98,   100] loss: 0.741\n",
      "[98,   200] loss: 0.790\n",
      "[98,   300] loss: 0.769\n",
      "[98,   400] loss: 0.777\n",
      "[98,   500] loss: 0.818\n",
      "[98,   600] loss: 0.789\n",
      "[98,   700] loss: 0.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99,   100] loss: 0.755\n",
      "[99,   200] loss: 0.788\n",
      "[99,   300] loss: 0.791\n",
      "[99,   400] loss: 0.793\n",
      "[99,   500] loss: 0.845\n",
      "[99,   600] loss: 0.853\n",
      "[99,   700] loss: 0.824\n",
      "[100,   100] loss: 0.774\n",
      "[100,   200] loss: 0.745\n",
      "[100,   300] loss: 0.760\n",
      "[100,   400] loss: 0.784\n",
      "[100,   500] loss: 0.825\n",
      "[100,   600] loss: 0.781\n",
      "[100,   700] loss: 0.836\n",
      "[101,   100] loss: 0.743\n",
      "[101,   200] loss: 0.783\n",
      "[101,   300] loss: 0.801\n",
      "[101,   400] loss: 0.787\n",
      "[101,   500] loss: 0.817\n",
      "[101,   600] loss: 0.821\n",
      "[101,   700] loss: 0.791\n",
      "[102,   100] loss: 0.798\n",
      "[102,   200] loss: 0.785\n",
      "[102,   300] loss: 0.797\n",
      "[102,   400] loss: 0.825\n",
      "[102,   500] loss: 0.774\n",
      "[102,   600] loss: 0.804\n",
      "[102,   700] loss: 0.829\n",
      "[103,   100] loss: 0.803\n",
      "[103,   200] loss: 0.780\n",
      "[103,   300] loss: 0.758\n",
      "[103,   400] loss: 0.796\n",
      "[103,   500] loss: 0.815\n",
      "[103,   600] loss: 0.839\n",
      "[103,   700] loss: 0.813\n",
      "[104,   100] loss: 0.765\n",
      "[104,   200] loss: 0.797\n",
      "[104,   300] loss: 0.792\n",
      "[104,   400] loss: 0.819\n",
      "[104,   500] loss: 0.790\n",
      "[104,   600] loss: 0.824\n",
      "[104,   700] loss: 0.806\n",
      "[105,   100] loss: 0.770\n",
      "[105,   200] loss: 0.763\n",
      "[105,   300] loss: 0.807\n",
      "[105,   400] loss: 0.795\n",
      "[105,   500] loss: 0.784\n",
      "[105,   600] loss: 0.800\n",
      "[105,   700] loss: 0.828\n",
      "[106,   100] loss: 0.728\n",
      "[106,   200] loss: 0.788\n",
      "[106,   300] loss: 0.793\n",
      "[106,   400] loss: 0.775\n",
      "[106,   500] loss: 0.805\n",
      "[106,   600] loss: 0.819\n",
      "[106,   700] loss: 0.813\n",
      "[107,   100] loss: 0.786\n",
      "[107,   200] loss: 0.770\n",
      "[107,   300] loss: 0.828\n",
      "[107,   400] loss: 0.785\n",
      "[107,   500] loss: 0.796\n",
      "[107,   600] loss: 0.821\n",
      "[107,   700] loss: 0.808\n",
      "[108,   100] loss: 0.751\n",
      "[108,   200] loss: 0.770\n",
      "[108,   300] loss: 0.798\n",
      "[108,   400] loss: 0.809\n",
      "[108,   500] loss: 0.795\n",
      "[108,   600] loss: 0.835\n",
      "[108,   700] loss: 0.817\n",
      "[109,   100] loss: 0.742\n",
      "[109,   200] loss: 0.767\n",
      "[109,   300] loss: 0.813\n",
      "[109,   400] loss: 0.781\n",
      "[109,   500] loss: 0.808\n",
      "[109,   600] loss: 0.797\n",
      "[109,   700] loss: 0.817\n",
      "[110,   100] loss: 0.779\n",
      "[110,   200] loss: 0.785\n",
      "[110,   300] loss: 0.805\n",
      "[110,   400] loss: 0.775\n",
      "[110,   500] loss: 0.833\n",
      "[110,   600] loss: 0.811\n",
      "[110,   700] loss: 0.783\n",
      "[111,   100] loss: 0.791\n",
      "[111,   200] loss: 0.789\n",
      "[111,   300] loss: 0.828\n",
      "[111,   400] loss: 0.815\n",
      "[111,   500] loss: 0.785\n",
      "[111,   600] loss: 0.810\n",
      "[111,   700] loss: 0.822\n",
      "[112,   100] loss: 0.756\n",
      "[112,   200] loss: 0.786\n",
      "[112,   300] loss: 0.761\n",
      "[112,   400] loss: 0.785\n",
      "[112,   500] loss: 0.815\n",
      "[112,   600] loss: 0.825\n",
      "[112,   700] loss: 0.826\n",
      "[113,   100] loss: 0.776\n",
      "[113,   200] loss: 0.754\n",
      "[113,   300] loss: 0.768\n",
      "[113,   400] loss: 0.779\n",
      "[113,   500] loss: 0.801\n",
      "[113,   600] loss: 0.799\n",
      "[113,   700] loss: 0.830\n",
      "[114,   100] loss: 0.732\n",
      "[114,   200] loss: 0.786\n",
      "[114,   300] loss: 0.767\n",
      "[114,   400] loss: 0.811\n",
      "[114,   500] loss: 0.766\n",
      "[114,   600] loss: 0.803\n",
      "[114,   700] loss: 0.836\n",
      "[115,   100] loss: 0.767\n",
      "[115,   200] loss: 0.755\n",
      "[115,   300] loss: 0.771\n",
      "[115,   400] loss: 0.776\n",
      "[115,   500] loss: 0.845\n",
      "[115,   600] loss: 0.779\n",
      "[115,   700] loss: 0.814\n",
      "[116,   100] loss: 0.785\n",
      "[116,   200] loss: 0.770\n",
      "[116,   300] loss: 0.799\n",
      "[116,   400] loss: 0.803\n",
      "[116,   500] loss: 0.793\n",
      "[116,   600] loss: 0.805\n",
      "[116,   700] loss: 0.796\n",
      "[117,   100] loss: 0.785\n",
      "[117,   200] loss: 0.758\n",
      "[117,   300] loss: 0.802\n",
      "[117,   400] loss: 0.775\n",
      "[117,   500] loss: 0.814\n",
      "[117,   600] loss: 0.811\n",
      "[117,   700] loss: 0.798\n",
      "[118,   100] loss: 0.771\n",
      "[118,   200] loss: 0.779\n",
      "[118,   300] loss: 0.777\n",
      "[118,   400] loss: 0.753\n",
      "[118,   500] loss: 0.823\n",
      "[118,   600] loss: 0.792\n",
      "[118,   700] loss: 0.814\n",
      "[119,   100] loss: 0.796\n",
      "[119,   200] loss: 0.753\n",
      "[119,   300] loss: 0.803\n",
      "[119,   400] loss: 0.829\n",
      "[119,   500] loss: 0.813\n",
      "[119,   600] loss: 0.799\n",
      "[119,   700] loss: 0.781\n",
      "[120,   100] loss: 0.749\n",
      "[120,   200] loss: 0.775\n",
      "[120,   300] loss: 0.788\n",
      "[120,   400] loss: 0.821\n",
      "[120,   500] loss: 0.781\n",
      "[120,   600] loss: 0.796\n",
      "[120,   700] loss: 0.806\n",
      "[121,   100] loss: 0.770\n",
      "[121,   200] loss: 0.761\n",
      "[121,   300] loss: 0.801\n",
      "[121,   400] loss: 0.795\n",
      "[121,   500] loss: 0.811\n",
      "[121,   600] loss: 0.800\n",
      "[121,   700] loss: 0.805\n",
      "[122,   100] loss: 0.787\n",
      "[122,   200] loss: 0.784\n",
      "[122,   300] loss: 0.784\n",
      "[122,   400] loss: 0.822\n",
      "[122,   500] loss: 0.804\n",
      "[122,   600] loss: 0.817\n",
      "[122,   700] loss: 0.794\n",
      "[123,   100] loss: 0.758\n",
      "[123,   200] loss: 0.743\n",
      "[123,   300] loss: 0.786\n",
      "[123,   400] loss: 0.779\n",
      "[123,   500] loss: 0.810\n",
      "[123,   600] loss: 0.832\n",
      "[123,   700] loss: 0.784\n",
      "[124,   100] loss: 0.746\n",
      "[124,   200] loss: 0.755\n",
      "[124,   300] loss: 0.793\n",
      "[124,   400] loss: 0.802\n",
      "[124,   500] loss: 0.797\n",
      "[124,   600] loss: 0.793\n",
      "[124,   700] loss: 0.806\n",
      "[125,   100] loss: 0.766\n",
      "[125,   200] loss: 0.758\n",
      "[125,   300] loss: 0.800\n",
      "[125,   400] loss: 0.770\n",
      "[125,   500] loss: 0.813\n",
      "[125,   600] loss: 0.795\n",
      "[125,   700] loss: 0.819\n",
      "[126,   100] loss: 0.739\n",
      "[126,   200] loss: 0.795\n",
      "[126,   300] loss: 0.763\n",
      "[126,   400] loss: 0.784\n",
      "[126,   500] loss: 0.793\n",
      "[126,   600] loss: 0.821\n",
      "[126,   700] loss: 0.815\n",
      "[127,   100] loss: 0.742\n",
      "[127,   200] loss: 0.771\n",
      "[127,   300] loss: 0.789\n",
      "[127,   400] loss: 0.791\n",
      "[127,   500] loss: 0.812\n",
      "[127,   600] loss: 0.819\n",
      "[127,   700] loss: 0.794\n",
      "[128,   100] loss: 0.732\n",
      "[128,   200] loss: 0.769\n",
      "[128,   300] loss: 0.811\n",
      "[128,   400] loss: 0.795\n",
      "[128,   500] loss: 0.811\n",
      "[128,   600] loss: 0.782\n",
      "[128,   700] loss: 0.825\n",
      "[129,   100] loss: 0.761\n",
      "[129,   200] loss: 0.798\n",
      "[129,   300] loss: 0.791\n",
      "[129,   400] loss: 0.798\n",
      "[129,   500] loss: 0.798\n",
      "[129,   600] loss: 0.797\n",
      "[129,   700] loss: 0.804\n",
      "[130,   100] loss: 0.742\n",
      "[130,   200] loss: 0.751\n",
      "[130,   300] loss: 0.777\n",
      "[130,   400] loss: 0.813\n",
      "[130,   500] loss: 0.820\n",
      "[130,   600] loss: 0.804\n",
      "[130,   700] loss: 0.786\n",
      "[131,   100] loss: 0.740\n",
      "[131,   200] loss: 0.815\n",
      "[131,   300] loss: 0.800\n",
      "[131,   400] loss: 0.772\n",
      "[131,   500] loss: 0.804\n",
      "[131,   600] loss: 0.802\n",
      "[131,   700] loss: 0.807\n",
      "[132,   100] loss: 0.747\n",
      "[132,   200] loss: 0.786\n",
      "[132,   300] loss: 0.790\n",
      "[132,   400] loss: 0.793\n",
      "[132,   500] loss: 0.803\n",
      "[132,   600] loss: 0.785\n",
      "[132,   700] loss: 0.809\n",
      "[133,   100] loss: 0.766\n",
      "[133,   200] loss: 0.782\n",
      "[133,   300] loss: 0.795\n",
      "[133,   400] loss: 0.813\n",
      "[133,   500] loss: 0.812\n",
      "[133,   600] loss: 0.797\n",
      "[133,   700] loss: 0.793\n",
      "[134,   100] loss: 0.754\n",
      "[134,   200] loss: 0.777\n",
      "[134,   300] loss: 0.770\n",
      "[134,   400] loss: 0.794\n",
      "[134,   500] loss: 0.812\n",
      "[134,   600] loss: 0.788\n",
      "[134,   700] loss: 0.803\n",
      "[135,   100] loss: 0.792\n",
      "[135,   200] loss: 0.790\n",
      "[135,   300] loss: 0.774\n",
      "[135,   400] loss: 0.786\n",
      "[135,   500] loss: 0.813\n",
      "[135,   600] loss: 0.828\n",
      "[135,   700] loss: 0.812\n",
      "[136,   100] loss: 0.734\n",
      "[136,   200] loss: 0.780\n",
      "[136,   300] loss: 0.783\n",
      "[136,   400] loss: 0.813\n",
      "[136,   500] loss: 0.806\n",
      "[136,   600] loss: 0.820\n",
      "[136,   700] loss: 0.815\n",
      "[137,   100] loss: 0.749\n",
      "[137,   200] loss: 0.742\n",
      "[137,   300] loss: 0.789\n",
      "[137,   400] loss: 0.806\n",
      "[137,   500] loss: 0.809\n",
      "[137,   600] loss: 0.824\n",
      "[137,   700] loss: 0.803\n",
      "[138,   100] loss: 0.752\n",
      "[138,   200] loss: 0.762\n",
      "[138,   300] loss: 0.800\n",
      "[138,   400] loss: 0.820\n",
      "[138,   500] loss: 0.807\n",
      "[138,   600] loss: 0.806\n",
      "[138,   700] loss: 0.812\n",
      "[139,   100] loss: 0.792\n",
      "[139,   200] loss: 0.751\n",
      "[139,   300] loss: 0.766\n",
      "[139,   400] loss: 0.814\n",
      "[139,   500] loss: 0.809\n",
      "[139,   600] loss: 0.808\n",
      "[139,   700] loss: 0.815\n",
      "[140,   100] loss: 0.730\n",
      "[140,   200] loss: 0.735\n",
      "[140,   300] loss: 0.792\n",
      "[140,   400] loss: 0.796\n",
      "[140,   500] loss: 0.794\n",
      "[140,   600] loss: 0.790\n",
      "[140,   700] loss: 0.827\n",
      "[141,   100] loss: 0.775\n",
      "[141,   200] loss: 0.783\n",
      "[141,   300] loss: 0.790\n",
      "[141,   400] loss: 0.821\n",
      "[141,   500] loss: 0.805\n",
      "[141,   600] loss: 0.827\n",
      "[141,   700] loss: 0.822\n",
      "[142,   100] loss: 0.730\n",
      "[142,   200] loss: 0.783\n",
      "[142,   300] loss: 0.782\n",
      "[142,   400] loss: 0.773\n",
      "[142,   500] loss: 0.771\n",
      "[142,   600] loss: 0.787\n",
      "[142,   700] loss: 0.839\n",
      "[143,   100] loss: 0.752\n",
      "[143,   200] loss: 0.795\n",
      "[143,   300] loss: 0.797\n",
      "[143,   400] loss: 0.802\n",
      "[143,   500] loss: 0.796\n",
      "[143,   600] loss: 0.782\n",
      "[143,   700] loss: 0.809\n",
      "[144,   100] loss: 0.739\n",
      "[144,   200] loss: 0.783\n",
      "[144,   300] loss: 0.766\n",
      "[144,   400] loss: 0.772\n",
      "[144,   500] loss: 0.830\n",
      "[144,   600] loss: 0.789\n",
      "[144,   700] loss: 0.815\n",
      "[145,   100] loss: 0.723\n",
      "[145,   200] loss: 0.758\n",
      "[145,   300] loss: 0.782\n",
      "[145,   400] loss: 0.810\n",
      "[145,   500] loss: 0.808\n",
      "[145,   600] loss: 0.822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145,   700] loss: 0.818\n",
      "[146,   100] loss: 0.729\n",
      "[146,   200] loss: 0.785\n",
      "[146,   300] loss: 0.793\n",
      "[146,   400] loss: 0.778\n",
      "[146,   500] loss: 0.796\n",
      "[146,   600] loss: 0.787\n",
      "[146,   700] loss: 0.801\n",
      "[147,   100] loss: 0.776\n",
      "[147,   200] loss: 0.756\n",
      "[147,   300] loss: 0.818\n",
      "[147,   400] loss: 0.789\n",
      "[147,   500] loss: 0.788\n",
      "[147,   600] loss: 0.798\n",
      "[147,   700] loss: 0.825\n",
      "[148,   100] loss: 0.774\n",
      "[148,   200] loss: 0.763\n",
      "[148,   300] loss: 0.786\n",
      "[148,   400] loss: 0.772\n",
      "[148,   500] loss: 0.788\n",
      "[148,   600] loss: 0.815\n",
      "[148,   700] loss: 0.805\n",
      "[149,   100] loss: 0.745\n",
      "[149,   200] loss: 0.761\n",
      "[149,   300] loss: 0.811\n",
      "[149,   400] loss: 0.803\n",
      "[149,   500] loss: 0.791\n",
      "[149,   600] loss: 0.788\n",
      "[149,   700] loss: 0.820\n",
      "[150,   100] loss: 0.784\n",
      "[150,   200] loss: 0.789\n",
      "[150,   300] loss: 0.767\n",
      "[150,   400] loss: 0.807\n",
      "[150,   500] loss: 0.782\n",
      "[150,   600] loss: 0.778\n",
      "[150,   700] loss: 0.821\n",
      "[151,   100] loss: 0.775\n",
      "[151,   200] loss: 0.735\n",
      "[151,   300] loss: 0.795\n",
      "[151,   400] loss: 0.799\n",
      "[151,   500] loss: 0.797\n",
      "[151,   600] loss: 0.817\n",
      "[151,   700] loss: 0.802\n",
      "[152,   100] loss: 0.763\n",
      "[152,   200] loss: 0.762\n",
      "[152,   300] loss: 0.758\n",
      "[152,   400] loss: 0.773\n",
      "[152,   500] loss: 0.772\n",
      "[152,   600] loss: 0.802\n",
      "[152,   700] loss: 0.800\n",
      "[153,   100] loss: 0.771\n",
      "[153,   200] loss: 0.763\n",
      "[153,   300] loss: 0.773\n",
      "[153,   400] loss: 0.784\n",
      "[153,   500] loss: 0.812\n",
      "[153,   600] loss: 0.800\n",
      "[153,   700] loss: 0.779\n",
      "[154,   100] loss: 0.755\n",
      "[154,   200] loss: 0.789\n",
      "[154,   300] loss: 0.808\n",
      "[154,   400] loss: 0.807\n",
      "[154,   500] loss: 0.818\n",
      "[154,   600] loss: 0.792\n",
      "[154,   700] loss: 0.798\n",
      "[155,   100] loss: 0.764\n",
      "[155,   200] loss: 0.772\n",
      "[155,   300] loss: 0.778\n",
      "[155,   400] loss: 0.776\n",
      "[155,   500] loss: 0.809\n",
      "[155,   600] loss: 0.777\n",
      "[155,   700] loss: 0.800\n",
      "[156,   100] loss: 0.750\n",
      "[156,   200] loss: 0.758\n",
      "[156,   300] loss: 0.812\n",
      "[156,   400] loss: 0.802\n",
      "[156,   500] loss: 0.829\n",
      "[156,   600] loss: 0.794\n",
      "[156,   700] loss: 0.821\n",
      "[157,   100] loss: 0.756\n",
      "[157,   200] loss: 0.778\n",
      "[157,   300] loss: 0.782\n",
      "[157,   400] loss: 0.768\n",
      "[157,   500] loss: 0.804\n",
      "[157,   600] loss: 0.821\n",
      "[157,   700] loss: 0.809\n",
      "[158,   100] loss: 0.764\n",
      "[158,   200] loss: 0.743\n",
      "[158,   300] loss: 0.799\n",
      "[158,   400] loss: 0.823\n",
      "[158,   500] loss: 0.824\n",
      "[158,   600] loss: 0.786\n",
      "[158,   700] loss: 0.822\n",
      "[159,   100] loss: 0.773\n",
      "[159,   200] loss: 0.779\n",
      "[159,   300] loss: 0.784\n",
      "[159,   400] loss: 0.771\n",
      "[159,   500] loss: 0.823\n",
      "[159,   600] loss: 0.804\n",
      "[159,   700] loss: 0.832\n",
      "[160,   100] loss: 0.765\n",
      "[160,   200] loss: 0.752\n",
      "[160,   300] loss: 0.773\n",
      "[160,   400] loss: 0.802\n",
      "[160,   500] loss: 0.788\n",
      "[160,   600] loss: 0.826\n",
      "[160,   700] loss: 0.813\n",
      "[161,   100] loss: 0.756\n",
      "[161,   200] loss: 0.774\n",
      "[161,   300] loss: 0.776\n",
      "[161,   400] loss: 0.785\n",
      "[161,   500] loss: 0.784\n",
      "[161,   600] loss: 0.796\n",
      "[161,   700] loss: 0.817\n",
      "[162,   100] loss: 0.752\n",
      "[162,   200] loss: 0.763\n",
      "[162,   300] loss: 0.813\n",
      "[162,   400] loss: 0.794\n",
      "[162,   500] loss: 0.780\n",
      "[162,   600] loss: 0.817\n",
      "[162,   700] loss: 0.792\n",
      "[163,   100] loss: 0.773\n",
      "[163,   200] loss: 0.778\n",
      "[163,   300] loss: 0.772\n",
      "[163,   400] loss: 0.798\n",
      "[163,   500] loss: 0.826\n",
      "[163,   600] loss: 0.807\n",
      "[163,   700] loss: 0.807\n",
      "[164,   100] loss: 0.785\n",
      "[164,   200] loss: 0.789\n",
      "[164,   300] loss: 0.806\n",
      "[164,   400] loss: 0.772\n",
      "[164,   500] loss: 0.775\n",
      "[164,   600] loss: 0.817\n",
      "[164,   700] loss: 0.806\n",
      "[165,   100] loss: 0.741\n",
      "[165,   200] loss: 0.764\n",
      "[165,   300] loss: 0.810\n",
      "[165,   400] loss: 0.756\n",
      "[165,   500] loss: 0.823\n",
      "[165,   600] loss: 0.808\n",
      "[165,   700] loss: 0.820\n",
      "[166,   100] loss: 0.731\n",
      "[166,   200] loss: 0.774\n",
      "[166,   300] loss: 0.777\n",
      "[166,   400] loss: 0.789\n",
      "[166,   500] loss: 0.793\n",
      "[166,   600] loss: 0.825\n",
      "[166,   700] loss: 0.830\n",
      "[167,   100] loss: 0.757\n",
      "[167,   200] loss: 0.778\n",
      "[167,   300] loss: 0.786\n",
      "[167,   400] loss: 0.806\n",
      "[167,   500] loss: 0.801\n",
      "[167,   600] loss: 0.794\n",
      "[167,   700] loss: 0.816\n",
      "[168,   100] loss: 0.754\n",
      "[168,   200] loss: 0.794\n",
      "[168,   300] loss: 0.777\n",
      "[168,   400] loss: 0.775\n",
      "[168,   500] loss: 0.791\n",
      "[168,   600] loss: 0.854\n",
      "[168,   700] loss: 0.794\n",
      "[169,   100] loss: 0.742\n",
      "[169,   200] loss: 0.759\n",
      "[169,   300] loss: 0.795\n",
      "[169,   400] loss: 0.808\n",
      "[169,   500] loss: 0.806\n",
      "[169,   600] loss: 0.794\n",
      "[169,   700] loss: 0.797\n",
      "[170,   100] loss: 0.725\n",
      "[170,   200] loss: 0.775\n",
      "[170,   300] loss: 0.786\n",
      "[170,   400] loss: 0.801\n",
      "[170,   500] loss: 0.799\n",
      "[170,   600] loss: 0.796\n",
      "[170,   700] loss: 0.818\n",
      "[171,   100] loss: 0.770\n",
      "[171,   200] loss: 0.769\n",
      "[171,   300] loss: 0.790\n",
      "[171,   400] loss: 0.811\n",
      "[171,   500] loss: 0.812\n",
      "[171,   600] loss: 0.781\n",
      "[171,   700] loss: 0.777\n",
      "[172,   100] loss: 0.753\n",
      "[172,   200] loss: 0.779\n",
      "[172,   300] loss: 0.766\n",
      "[172,   400] loss: 0.763\n",
      "[172,   500] loss: 0.794\n",
      "[172,   600] loss: 0.796\n",
      "[172,   700] loss: 0.822\n",
      "[173,   100] loss: 0.798\n",
      "[173,   200] loss: 0.786\n",
      "[173,   300] loss: 0.790\n",
      "[173,   400] loss: 0.779\n",
      "[173,   500] loss: 0.814\n",
      "[173,   600] loss: 0.820\n",
      "[173,   700] loss: 0.805\n",
      "[174,   100] loss: 0.759\n",
      "[174,   200] loss: 0.764\n",
      "[174,   300] loss: 0.781\n",
      "[174,   400] loss: 0.795\n",
      "[174,   500] loss: 0.806\n",
      "[174,   600] loss: 0.817\n",
      "[174,   700] loss: 0.794\n",
      "[175,   100] loss: 0.772\n",
      "[175,   200] loss: 0.781\n",
      "[175,   300] loss: 0.775\n",
      "[175,   400] loss: 0.792\n",
      "[175,   500] loss: 0.800\n",
      "[175,   600] loss: 0.814\n",
      "[175,   700] loss: 0.805\n",
      "[176,   100] loss: 0.780\n",
      "[176,   200] loss: 0.759\n",
      "[176,   300] loss: 0.774\n",
      "[176,   400] loss: 0.801\n",
      "[176,   500] loss: 0.817\n",
      "[176,   600] loss: 0.814\n",
      "[176,   700] loss: 0.828\n",
      "[177,   100] loss: 0.772\n",
      "[177,   200] loss: 0.770\n",
      "[177,   300] loss: 0.795\n",
      "[177,   400] loss: 0.786\n",
      "[177,   500] loss: 0.823\n",
      "[177,   600] loss: 0.798\n",
      "[177,   700] loss: 0.802\n",
      "[178,   100] loss: 0.777\n",
      "[178,   200] loss: 0.752\n",
      "[178,   300] loss: 0.794\n",
      "[178,   400] loss: 0.788\n",
      "[178,   500] loss: 0.801\n",
      "[178,   600] loss: 0.787\n",
      "[178,   700] loss: 0.800\n",
      "[179,   100] loss: 0.760\n",
      "[179,   200] loss: 0.765\n",
      "[179,   300] loss: 0.781\n",
      "[179,   400] loss: 0.801\n",
      "[179,   500] loss: 0.813\n",
      "[179,   600] loss: 0.785\n",
      "[179,   700] loss: 0.840\n",
      "[180,   100] loss: 0.768\n",
      "[180,   200] loss: 0.766\n",
      "[180,   300] loss: 0.806\n",
      "[180,   400] loss: 0.818\n",
      "[180,   500] loss: 0.795\n",
      "[180,   600] loss: 0.816\n",
      "[180,   700] loss: 0.799\n",
      "[181,   100] loss: 0.802\n",
      "[181,   200] loss: 0.809\n",
      "[181,   300] loss: 0.762\n",
      "[181,   400] loss: 0.776\n",
      "[181,   500] loss: 0.779\n",
      "[181,   600] loss: 0.813\n",
      "[181,   700] loss: 0.808\n",
      "[182,   100] loss: 0.759\n",
      "[182,   200] loss: 0.781\n",
      "[182,   300] loss: 0.774\n",
      "[182,   400] loss: 0.785\n",
      "[182,   500] loss: 0.798\n",
      "[182,   600] loss: 0.838\n",
      "[182,   700] loss: 0.808\n",
      "[183,   100] loss: 0.750\n",
      "[183,   200] loss: 0.756\n",
      "[183,   300] loss: 0.777\n",
      "[183,   400] loss: 0.807\n",
      "[183,   500] loss: 0.787\n",
      "[183,   600] loss: 0.803\n",
      "[183,   700] loss: 0.804\n",
      "[184,   100] loss: 0.738\n",
      "[184,   200] loss: 0.764\n",
      "[184,   300] loss: 0.778\n",
      "[184,   400] loss: 0.801\n",
      "[184,   500] loss: 0.799\n",
      "[184,   600] loss: 0.807\n",
      "[184,   700] loss: 0.817\n",
      "[185,   100] loss: 0.757\n",
      "[185,   200] loss: 0.785\n",
      "[185,   300] loss: 0.747\n",
      "[185,   400] loss: 0.789\n",
      "[185,   500] loss: 0.831\n",
      "[185,   600] loss: 0.814\n",
      "[185,   700] loss: 0.805\n",
      "[186,   100] loss: 0.793\n",
      "[186,   200] loss: 0.772\n",
      "[186,   300] loss: 0.786\n",
      "[186,   400] loss: 0.783\n",
      "[186,   500] loss: 0.812\n",
      "[186,   600] loss: 0.808\n",
      "[186,   700] loss: 0.800\n",
      "[187,   100] loss: 0.744\n",
      "[187,   200] loss: 0.779\n",
      "[187,   300] loss: 0.776\n",
      "[187,   400] loss: 0.788\n",
      "[187,   500] loss: 0.797\n",
      "[187,   600] loss: 0.794\n",
      "[187,   700] loss: 0.799\n",
      "[188,   100] loss: 0.763\n",
      "[188,   200] loss: 0.771\n",
      "[188,   300] loss: 0.769\n",
      "[188,   400] loss: 0.773\n",
      "[188,   500] loss: 0.791\n",
      "[188,   600] loss: 0.812\n",
      "[188,   700] loss: 0.765\n",
      "[189,   100] loss: 0.786\n",
      "[189,   200] loss: 0.745\n",
      "[189,   300] loss: 0.789\n",
      "[189,   400] loss: 0.774\n",
      "[189,   500] loss: 0.814\n",
      "[189,   600] loss: 0.785\n",
      "[189,   700] loss: 0.814\n",
      "[190,   100] loss: 0.768\n",
      "[190,   200] loss: 0.778\n",
      "[190,   300] loss: 0.774\n",
      "[190,   400] loss: 0.770\n",
      "[190,   500] loss: 0.823\n",
      "[190,   600] loss: 0.789\n",
      "[190,   700] loss: 0.816\n",
      "[191,   100] loss: 0.715\n",
      "[191,   200] loss: 0.769\n",
      "[191,   300] loss: 0.757\n",
      "[191,   400] loss: 0.788\n",
      "[191,   500] loss: 0.815\n",
      "[191,   600] loss: 0.796\n",
      "[191,   700] loss: 0.823\n",
      "[192,   100] loss: 0.753\n",
      "[192,   200] loss: 0.784\n",
      "[192,   300] loss: 0.765\n",
      "[192,   400] loss: 0.772\n",
      "[192,   500] loss: 0.807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[192,   600] loss: 0.805\n",
      "[192,   700] loss: 0.825\n",
      "[193,   100] loss: 0.794\n",
      "[193,   200] loss: 0.766\n",
      "[193,   300] loss: 0.778\n",
      "[193,   400] loss: 0.786\n",
      "[193,   500] loss: 0.808\n",
      "[193,   600] loss: 0.813\n",
      "[193,   700] loss: 0.823\n",
      "[194,   100] loss: 0.758\n",
      "[194,   200] loss: 0.759\n",
      "[194,   300] loss: 0.794\n",
      "[194,   400] loss: 0.801\n",
      "[194,   500] loss: 0.819\n",
      "[194,   600] loss: 0.799\n",
      "[194,   700] loss: 0.813\n",
      "[195,   100] loss: 0.793\n",
      "[195,   200] loss: 0.789\n",
      "[195,   300] loss: 0.761\n",
      "[195,   400] loss: 0.803\n",
      "[195,   500] loss: 0.799\n",
      "[195,   600] loss: 0.801\n",
      "[195,   700] loss: 0.821\n",
      "[196,   100] loss: 0.743\n",
      "[196,   200] loss: 0.766\n",
      "[196,   300] loss: 0.800\n",
      "[196,   400] loss: 0.815\n",
      "[196,   500] loss: 0.825\n",
      "[196,   600] loss: 0.799\n",
      "[196,   700] loss: 0.818\n",
      "[197,   100] loss: 0.748\n",
      "[197,   200] loss: 0.767\n",
      "[197,   300] loss: 0.753\n",
      "[197,   400] loss: 0.779\n",
      "[197,   500] loss: 0.793\n",
      "[197,   600] loss: 0.825\n",
      "[197,   700] loss: 0.795\n",
      "[198,   100] loss: 0.798\n",
      "[198,   200] loss: 0.780\n",
      "[198,   300] loss: 0.805\n",
      "[198,   400] loss: 0.795\n",
      "[198,   500] loss: 0.822\n",
      "[198,   600] loss: 0.799\n",
      "[198,   700] loss: 0.803\n",
      "[199,   100] loss: 0.816\n",
      "[199,   200] loss: 0.771\n",
      "[199,   300] loss: 0.797\n",
      "[199,   400] loss: 0.787\n",
      "[199,   500] loss: 0.811\n",
      "[199,   600] loss: 0.816\n",
      "[199,   700] loss: 0.807\n",
      "[200,   100] loss: 0.814\n",
      "[200,   200] loss: 0.750\n",
      "[200,   300] loss: 0.779\n",
      "[200,   400] loss: 0.794\n",
      "[200,   500] loss: 0.823\n",
      "[200,   600] loss: 0.814\n",
      "[200,   700] loss: 0.813\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs) \n",
    "        loss =  criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:01:24.889122Z",
     "start_time": "2020-10-08T00:00:56.397102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 61.200000 %\n",
      "Accuracy of   car : 76.400000 %\n",
      "Accuracy of  bird : 56.700000 %\n",
      "Accuracy of   cat : 74.400000 %\n",
      "Accuracy of  deer : 65.600000 %\n",
      "Accuracy of   dog : 48.200000 %\n",
      "Accuracy of  frog : 69.600000 %\n",
      "Accuracy of horse : 31.000000 %\n",
      "Accuracy of  ship : 54.400000 %\n",
      "Accuracy of truck : 55.100000 %\n",
      "Mean Accuracy :  59.26\n"
     ]
    }
   ],
   "source": [
    "class_correct = np.zeros(10)\n",
    "class_total = np.zeros(10)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print('Mean Accuracy : ', 100*np.sum(class_correct)/np.sum(class_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
