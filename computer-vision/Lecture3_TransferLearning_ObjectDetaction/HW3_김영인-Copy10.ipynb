{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Challange - 김영인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. wide resnet 50-2\n",
    "2. \\+ Data Augmentation(RandomResizedCrop, RandomHorizontalFlip)\n",
    "3. \\+ Data Normalize\n",
    "4. \\+ regularization(dropout, weight decay)\n",
    "5. \\+ Optimizer(momentum, scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:05:09.553550Z",
     "start_time": "2020-10-08T00:05:09.542245Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models, datasets\n",
    "\n",
    "random_seed = 4332\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device1 = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = device0\n",
    "print(f\"device: {device}\") if torch.cuda.is_available() else print(\"device: cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper parameter Setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:05:09.944115Z",
     "start_time": "2020-10-08T00:05:09.938274Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "scheduler_step = 60\n",
    "scheduler_gamma = 0.2\n",
    "training_epochs = 200\n",
    "batch_size = 64\n",
    "momentum = 0.9\n",
    "weight_decay = 5e-4\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:05:12.790026Z",
     "start_time": "2020-10-08T00:05:11.210641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(224), # data augmentation, 224: image size, ImageNet pretrained model에 맞추기 위해서 224 size로 설정\n",
    "     transforms.RandomHorizontalFlip(), # data augmentation, 좌우로 대칭\n",
    "     transforms.ToTensor(), # numpy array를 pytorch tensor로 바꿔주는 역할\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) # dataset의 mean, std를 이용해서 -1~1 로 normalize\n",
    "    ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                      download=True, transform=transforms.ToTensor())\n",
    "testloader = DataLoader(testset, batch_size=4,\n",
    "                                        shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Define pretrained model and fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:05:14.019310Z",
     "start_time": "2020-10-08T00:05:12.791536Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(models.wide_resnet50_2(pretrained=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:05:14.035050Z",
     "start_time": "2020-10-08T00:05:14.024293Z"
    }
   },
   "outputs": [],
   "source": [
    "class WideResNet(nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(WideResNet, self).__init__()\n",
    "        self.resnet = models.wide_resnet50_2(pretrained=True)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1000, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T00:05:18.331230Z",
     "start_time": "2020-10-08T00:05:14.037755Z"
    }
   },
   "outputs": [],
   "source": [
    "net = WideResNet()\n",
    "net = net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, \n",
    "                                      step_size = scheduler_step,\n",
    "                                      gamma = scheduler_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:29:47.050143Z",
     "start_time": "2020-10-08T00:05:18.333157Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 2.482\n",
      "[1,   200] loss: 2.171\n",
      "[1,   300] loss: 2.004\n",
      "[1,   400] loss: 1.910\n",
      "[1,   500] loss: 1.827\n",
      "[1,   600] loss: 1.807\n",
      "[1,   700] loss: 1.762\n",
      "[2,   100] loss: 1.706\n",
      "[2,   200] loss: 1.690\n",
      "[2,   300] loss: 1.642\n",
      "[2,   400] loss: 1.622\n",
      "[2,   500] loss: 1.611\n",
      "[2,   600] loss: 1.598\n",
      "[2,   700] loss: 1.545\n",
      "[3,   100] loss: 1.505\n",
      "[3,   200] loss: 1.491\n",
      "[3,   300] loss: 1.459\n",
      "[3,   400] loss: 1.397\n",
      "[3,   500] loss: 1.377\n",
      "[3,   600] loss: 1.338\n",
      "[3,   700] loss: 1.369\n",
      "[4,   100] loss: 1.299\n",
      "[4,   200] loss: 1.269\n",
      "[4,   300] loss: 1.268\n",
      "[4,   400] loss: 1.242\n",
      "[4,   500] loss: 1.271\n",
      "[4,   600] loss: 1.237\n",
      "[4,   700] loss: 1.231\n",
      "[5,   100] loss: 1.205\n",
      "[5,   200] loss: 1.168\n",
      "[5,   300] loss: 1.176\n",
      "[5,   400] loss: 1.187\n",
      "[5,   500] loss: 1.148\n",
      "[5,   600] loss: 1.184\n",
      "[5,   700] loss: 1.137\n",
      "[6,   100] loss: 1.119\n",
      "[6,   200] loss: 1.125\n",
      "[6,   300] loss: 1.116\n",
      "[6,   400] loss: 1.109\n",
      "[6,   500] loss: 1.114\n",
      "[6,   600] loss: 1.135\n",
      "[6,   700] loss: 1.096\n",
      "[7,   100] loss: 1.094\n",
      "[7,   200] loss: 1.089\n",
      "[7,   300] loss: 1.076\n",
      "[7,   400] loss: 1.106\n",
      "[7,   500] loss: 1.052\n",
      "[7,   600] loss: 1.059\n",
      "[7,   700] loss: 1.050\n",
      "[8,   100] loss: 1.029\n",
      "[8,   200] loss: 0.997\n",
      "[8,   300] loss: 1.042\n",
      "[8,   400] loss: 1.054\n",
      "[8,   500] loss: 1.016\n",
      "[8,   600] loss: 1.052\n",
      "[8,   700] loss: 1.063\n",
      "[9,   100] loss: 0.986\n",
      "[9,   200] loss: 0.998\n",
      "[9,   300] loss: 1.000\n",
      "[9,   400] loss: 1.013\n",
      "[9,   500] loss: 0.989\n",
      "[9,   600] loss: 1.029\n",
      "[9,   700] loss: 1.013\n",
      "[10,   100] loss: 0.978\n",
      "[10,   200] loss: 0.958\n",
      "[10,   300] loss: 0.976\n",
      "[10,   400] loss: 0.973\n",
      "[10,   500] loss: 0.979\n",
      "[10,   600] loss: 0.969\n",
      "[10,   700] loss: 1.005\n",
      "[11,   100] loss: 0.950\n",
      "[11,   200] loss: 0.958\n",
      "[11,   300] loss: 0.969\n",
      "[11,   400] loss: 0.946\n",
      "[11,   500] loss: 0.982\n",
      "[11,   600] loss: 0.984\n",
      "[11,   700] loss: 0.948\n",
      "[12,   100] loss: 0.954\n",
      "[12,   200] loss: 0.962\n",
      "[12,   300] loss: 0.954\n",
      "[12,   400] loss: 0.928\n",
      "[12,   500] loss: 0.935\n",
      "[12,   600] loss: 0.935\n",
      "[12,   700] loss: 0.959\n",
      "[13,   100] loss: 0.913\n",
      "[13,   200] loss: 0.915\n",
      "[13,   300] loss: 0.917\n",
      "[13,   400] loss: 0.946\n",
      "[13,   500] loss: 0.942\n",
      "[13,   600] loss: 0.963\n",
      "[13,   700] loss: 0.914\n",
      "[14,   100] loss: 0.884\n",
      "[14,   200] loss: 0.916\n",
      "[14,   300] loss: 0.926\n",
      "[14,   400] loss: 0.924\n",
      "[14,   500] loss: 0.929\n",
      "[14,   600] loss: 0.925\n",
      "[14,   700] loss: 0.908\n",
      "[15,   100] loss: 0.899\n",
      "[15,   200] loss: 0.908\n",
      "[15,   300] loss: 0.898\n",
      "[15,   400] loss: 0.957\n",
      "[15,   500] loss: 0.921\n",
      "[15,   600] loss: 0.923\n",
      "[15,   700] loss: 0.932\n",
      "[16,   100] loss: 0.885\n",
      "[16,   200] loss: 0.873\n",
      "[16,   300] loss: 0.925\n",
      "[16,   400] loss: 0.931\n",
      "[16,   500] loss: 0.936\n",
      "[16,   600] loss: 0.907\n",
      "[16,   700] loss: 0.924\n",
      "[17,   100] loss: 0.858\n",
      "[17,   200] loss: 0.880\n",
      "[17,   300] loss: 0.918\n",
      "[17,   400] loss: 0.905\n",
      "[17,   500] loss: 0.899\n",
      "[17,   600] loss: 0.905\n",
      "[17,   700] loss: 0.926\n",
      "[18,   100] loss: 0.891\n",
      "[18,   200] loss: 0.871\n",
      "[18,   300] loss: 0.891\n",
      "[18,   400] loss: 0.904\n",
      "[18,   500] loss: 0.887\n",
      "[18,   600] loss: 0.896\n",
      "[18,   700] loss: 0.896\n",
      "[19,   100] loss: 0.871\n",
      "[19,   200] loss: 0.878\n",
      "[19,   300] loss: 0.906\n",
      "[19,   400] loss: 0.882\n",
      "[19,   500] loss: 0.911\n",
      "[19,   600] loss: 0.915\n",
      "[19,   700] loss: 0.896\n",
      "[20,   100] loss: 0.837\n",
      "[20,   200] loss: 0.855\n",
      "[20,   300] loss: 0.889\n",
      "[20,   400] loss: 0.891\n",
      "[20,   500] loss: 0.883\n",
      "[20,   600] loss: 0.906\n",
      "[20,   700] loss: 0.893\n",
      "[21,   100] loss: 0.843\n",
      "[21,   200] loss: 0.845\n",
      "[21,   300] loss: 0.860\n",
      "[21,   400] loss: 0.879\n",
      "[21,   500] loss: 0.894\n",
      "[21,   600] loss: 0.892\n",
      "[21,   700] loss: 0.928\n",
      "[22,   100] loss: 0.856\n",
      "[22,   200] loss: 0.854\n",
      "[22,   300] loss: 0.857\n",
      "[22,   400] loss: 0.857\n",
      "[22,   500] loss: 0.897\n",
      "[22,   600] loss: 0.887\n",
      "[22,   700] loss: 0.921\n",
      "[23,   100] loss: 0.883\n",
      "[23,   200] loss: 0.866\n",
      "[23,   300] loss: 0.836\n",
      "[23,   400] loss: 0.863\n",
      "[23,   500] loss: 0.875\n",
      "[23,   600] loss: 0.876\n",
      "[23,   700] loss: 0.920\n",
      "[24,   100] loss: 0.858\n",
      "[24,   200] loss: 0.859\n",
      "[24,   300] loss: 0.865\n",
      "[24,   400] loss: 0.861\n",
      "[24,   500] loss: 0.843\n",
      "[24,   600] loss: 0.895\n",
      "[24,   700] loss: 0.853\n",
      "[25,   100] loss: 0.823\n",
      "[25,   200] loss: 0.851\n",
      "[25,   300] loss: 0.864\n",
      "[25,   400] loss: 0.823\n",
      "[25,   500] loss: 0.867\n",
      "[25,   600] loss: 0.902\n",
      "[25,   700] loss: 0.877\n",
      "[26,   100] loss: 0.860\n",
      "[26,   200] loss: 0.836\n",
      "[26,   300] loss: 0.850\n",
      "[26,   400] loss: 0.846\n",
      "[26,   500] loss: 0.851\n",
      "[26,   600] loss: 0.860\n",
      "[26,   700] loss: 0.854\n",
      "[27,   100] loss: 0.820\n",
      "[27,   200] loss: 0.852\n",
      "[27,   300] loss: 0.851\n",
      "[27,   400] loss: 0.848\n",
      "[27,   500] loss: 0.876\n",
      "[27,   600] loss: 0.865\n",
      "[27,   700] loss: 0.868\n",
      "[28,   100] loss: 0.813\n",
      "[28,   200] loss: 0.841\n",
      "[28,   300] loss: 0.846\n",
      "[28,   400] loss: 0.840\n",
      "[28,   500] loss: 0.853\n",
      "[28,   600] loss: 0.841\n",
      "[28,   700] loss: 0.868\n",
      "[29,   100] loss: 0.810\n",
      "[29,   200] loss: 0.841\n",
      "[29,   300] loss: 0.850\n",
      "[29,   400] loss: 0.844\n",
      "[29,   500] loss: 0.859\n",
      "[29,   600] loss: 0.830\n",
      "[29,   700] loss: 0.844\n",
      "[30,   100] loss: 0.843\n",
      "[30,   200] loss: 0.795\n",
      "[30,   300] loss: 0.867\n",
      "[30,   400] loss: 0.831\n",
      "[30,   500] loss: 0.828\n",
      "[30,   600] loss: 0.876\n",
      "[30,   700] loss: 0.867\n",
      "[31,   100] loss: 0.773\n",
      "[31,   200] loss: 0.818\n",
      "[31,   300] loss: 0.832\n",
      "[31,   400] loss: 0.869\n",
      "[31,   500] loss: 0.823\n",
      "[31,   600] loss: 0.893\n",
      "[31,   700] loss: 0.867\n",
      "[32,   100] loss: 0.837\n",
      "[32,   200] loss: 0.827\n",
      "[32,   300] loss: 0.835\n",
      "[32,   400] loss: 0.816\n",
      "[32,   500] loss: 0.860\n",
      "[32,   600] loss: 0.853\n",
      "[32,   700] loss: 0.869\n",
      "[33,   100] loss: 0.808\n",
      "[33,   200] loss: 0.818\n",
      "[33,   300] loss: 0.842\n",
      "[33,   400] loss: 0.835\n",
      "[33,   500] loss: 0.862\n",
      "[33,   600] loss: 0.856\n",
      "[33,   700] loss: 0.858\n",
      "[34,   100] loss: 0.800\n",
      "[34,   200] loss: 0.811\n",
      "[34,   300] loss: 0.845\n",
      "[34,   400] loss: 0.866\n",
      "[34,   500] loss: 0.840\n",
      "[34,   600] loss: 0.823\n",
      "[34,   700] loss: 0.870\n",
      "[35,   100] loss: 0.820\n",
      "[35,   200] loss: 0.838\n",
      "[35,   300] loss: 0.794\n",
      "[35,   400] loss: 0.824\n",
      "[35,   500] loss: 0.834\n",
      "[35,   600] loss: 0.855\n",
      "[35,   700] loss: 0.820\n",
      "[36,   100] loss: 0.799\n",
      "[36,   200] loss: 0.797\n",
      "[36,   300] loss: 0.820\n",
      "[36,   400] loss: 0.869\n",
      "[36,   500] loss: 0.823\n",
      "[36,   600] loss: 0.856\n",
      "[36,   700] loss: 0.854\n",
      "[37,   100] loss: 0.817\n",
      "[37,   200] loss: 0.815\n",
      "[37,   300] loss: 0.837\n",
      "[37,   400] loss: 0.828\n",
      "[37,   500] loss: 0.845\n",
      "[37,   600] loss: 0.847\n",
      "[37,   700] loss: 0.845\n",
      "[38,   100] loss: 0.793\n",
      "[38,   200] loss: 0.807\n",
      "[38,   300] loss: 0.813\n",
      "[38,   400] loss: 0.854\n",
      "[38,   500] loss: 0.845\n",
      "[38,   600] loss: 0.857\n",
      "[38,   700] loss: 0.820\n",
      "[39,   100] loss: 0.801\n",
      "[39,   200] loss: 0.824\n",
      "[39,   300] loss: 0.817\n",
      "[39,   400] loss: 0.818\n",
      "[39,   500] loss: 0.820\n",
      "[39,   600] loss: 0.835\n",
      "[39,   700] loss: 0.844\n",
      "[40,   100] loss: 0.781\n",
      "[40,   200] loss: 0.790\n",
      "[40,   300] loss: 0.812\n",
      "[40,   400] loss: 0.832\n",
      "[40,   500] loss: 0.827\n",
      "[40,   600] loss: 0.837\n",
      "[40,   700] loss: 0.853\n",
      "[41,   100] loss: 0.777\n",
      "[41,   200] loss: 0.823\n",
      "[41,   300] loss: 0.828\n",
      "[41,   400] loss: 0.811\n",
      "[41,   500] loss: 0.843\n",
      "[41,   600] loss: 0.861\n",
      "[41,   700] loss: 0.848\n",
      "[42,   100] loss: 0.802\n",
      "[42,   200] loss: 0.779\n",
      "[42,   300] loss: 0.814\n",
      "[42,   400] loss: 0.839\n",
      "[42,   500] loss: 0.838\n",
      "[42,   600] loss: 0.801\n",
      "[42,   700] loss: 0.828\n",
      "[43,   100] loss: 0.790\n",
      "[43,   200] loss: 0.847\n",
      "[43,   300] loss: 0.815\n",
      "[43,   400] loss: 0.829\n",
      "[43,   500] loss: 0.836\n",
      "[43,   600] loss: 0.809\n",
      "[43,   700] loss: 0.874\n",
      "[44,   100] loss: 0.798\n",
      "[44,   200] loss: 0.819\n",
      "[44,   300] loss: 0.791\n",
      "[44,   400] loss: 0.825\n",
      "[44,   500] loss: 0.852\n",
      "[44,   600] loss: 0.840\n",
      "[44,   700] loss: 0.825\n",
      "[45,   100] loss: 0.798\n",
      "[45,   200] loss: 0.773\n",
      "[45,   300] loss: 0.814\n",
      "[45,   400] loss: 0.830\n",
      "[45,   500] loss: 0.836\n",
      "[45,   600] loss: 0.815\n",
      "[45,   700] loss: 0.837\n",
      "[46,   100] loss: 0.806\n",
      "[46,   200] loss: 0.811\n",
      "[46,   300] loss: 0.834\n",
      "[46,   400] loss: 0.825\n",
      "[46,   500] loss: 0.816\n",
      "[46,   600] loss: 0.821\n",
      "[46,   700] loss: 0.793\n",
      "[47,   100] loss: 0.813\n",
      "[47,   200] loss: 0.820\n",
      "[47,   300] loss: 0.809\n",
      "[47,   400] loss: 0.806\n",
      "[47,   500] loss: 0.812\n",
      "[47,   600] loss: 0.849\n",
      "[47,   700] loss: 0.817\n",
      "[48,   100] loss: 0.775\n",
      "[48,   200] loss: 0.782\n",
      "[48,   300] loss: 0.806\n",
      "[48,   400] loss: 0.806\n",
      "[48,   500] loss: 0.824\n",
      "[48,   600] loss: 0.830\n",
      "[48,   700] loss: 0.841\n",
      "[49,   100] loss: 0.803\n",
      "[49,   200] loss: 0.792\n",
      "[49,   300] loss: 0.841\n",
      "[49,   400] loss: 0.823\n",
      "[49,   500] loss: 0.809\n",
      "[49,   600] loss: 0.831\n",
      "[49,   700] loss: 0.816\n",
      "[50,   100] loss: 0.769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50,   200] loss: 0.786\n",
      "[50,   300] loss: 0.837\n",
      "[50,   400] loss: 0.814\n",
      "[50,   500] loss: 0.807\n",
      "[50,   600] loss: 0.826\n",
      "[50,   700] loss: 0.828\n",
      "[51,   100] loss: 0.786\n",
      "[51,   200] loss: 0.800\n",
      "[51,   300] loss: 0.797\n",
      "[51,   400] loss: 0.814\n",
      "[51,   500] loss: 0.834\n",
      "[51,   600] loss: 0.852\n",
      "[51,   700] loss: 0.846\n",
      "[52,   100] loss: 0.763\n",
      "[52,   200] loss: 0.811\n",
      "[52,   300] loss: 0.795\n",
      "[52,   400] loss: 0.804\n",
      "[52,   500] loss: 0.824\n",
      "[52,   600] loss: 0.836\n",
      "[52,   700] loss: 0.844\n",
      "[53,   100] loss: 0.778\n",
      "[53,   200] loss: 0.789\n",
      "[53,   300] loss: 0.772\n",
      "[53,   400] loss: 0.782\n",
      "[53,   500] loss: 0.811\n",
      "[53,   600] loss: 0.837\n",
      "[53,   700] loss: 0.855\n",
      "[54,   100] loss: 0.790\n",
      "[54,   200] loss: 0.815\n",
      "[54,   300] loss: 0.821\n",
      "[54,   400] loss: 0.807\n",
      "[54,   500] loss: 0.832\n",
      "[54,   600] loss: 0.797\n",
      "[54,   700] loss: 0.833\n",
      "[55,   100] loss: 0.773\n",
      "[55,   200] loss: 0.794\n",
      "[55,   300] loss: 0.812\n",
      "[55,   400] loss: 0.826\n",
      "[55,   500] loss: 0.838\n",
      "[55,   600] loss: 0.813\n",
      "[55,   700] loss: 0.820\n",
      "[56,   100] loss: 0.754\n",
      "[56,   200] loss: 0.780\n",
      "[56,   300] loss: 0.810\n",
      "[56,   400] loss: 0.817\n",
      "[56,   500] loss: 0.850\n",
      "[56,   600] loss: 0.814\n",
      "[56,   700] loss: 0.856\n",
      "[57,   100] loss: 0.804\n",
      "[57,   200] loss: 0.770\n",
      "[57,   300] loss: 0.813\n",
      "[57,   400] loss: 0.822\n",
      "[57,   500] loss: 0.800\n",
      "[57,   600] loss: 0.840\n",
      "[57,   700] loss: 0.815\n",
      "[58,   100] loss: 0.792\n",
      "[58,   200] loss: 0.799\n",
      "[58,   300] loss: 0.816\n",
      "[58,   400] loss: 0.805\n",
      "[58,   500] loss: 0.815\n",
      "[58,   600] loss: 0.806\n",
      "[58,   700] loss: 0.814\n",
      "[59,   100] loss: 0.772\n",
      "[59,   200] loss: 0.793\n",
      "[59,   300] loss: 0.812\n",
      "[59,   400] loss: 0.800\n",
      "[59,   500] loss: 0.812\n",
      "[59,   600] loss: 0.835\n",
      "[59,   700] loss: 0.826\n",
      "[60,   100] loss: 0.822\n",
      "[60,   200] loss: 0.799\n",
      "[60,   300] loss: 0.792\n",
      "[60,   400] loss: 0.833\n",
      "[60,   500] loss: 0.780\n",
      "[60,   600] loss: 0.810\n",
      "[60,   700] loss: 0.815\n",
      "[61,   100] loss: 0.757\n",
      "[61,   200] loss: 0.788\n",
      "[61,   300] loss: 0.797\n",
      "[61,   400] loss: 0.839\n",
      "[61,   500] loss: 0.806\n",
      "[61,   600] loss: 0.825\n",
      "[61,   700] loss: 0.834\n",
      "[62,   100] loss: 0.792\n",
      "[62,   200] loss: 0.790\n",
      "[62,   300] loss: 0.804\n",
      "[62,   400] loss: 0.783\n",
      "[62,   500] loss: 0.811\n",
      "[62,   600] loss: 0.832\n",
      "[62,   700] loss: 0.802\n",
      "[63,   100] loss: 0.755\n",
      "[63,   200] loss: 0.788\n",
      "[63,   300] loss: 0.791\n",
      "[63,   400] loss: 0.821\n",
      "[63,   500] loss: 0.813\n",
      "[63,   600] loss: 0.817\n",
      "[63,   700] loss: 0.830\n",
      "[64,   100] loss: 0.783\n",
      "[64,   200] loss: 0.798\n",
      "[64,   300] loss: 0.802\n",
      "[64,   400] loss: 0.775\n",
      "[64,   500] loss: 0.824\n",
      "[64,   600] loss: 0.819\n",
      "[64,   700] loss: 0.815\n",
      "[65,   100] loss: 0.803\n",
      "[65,   200] loss: 0.755\n",
      "[65,   300] loss: 0.780\n",
      "[65,   400] loss: 0.786\n",
      "[65,   500] loss: 0.807\n",
      "[65,   600] loss: 0.847\n",
      "[65,   700] loss: 0.823\n",
      "[66,   100] loss: 0.761\n",
      "[66,   200] loss: 0.815\n",
      "[66,   300] loss: 0.793\n",
      "[66,   400] loss: 0.812\n",
      "[66,   500] loss: 0.800\n",
      "[66,   600] loss: 0.788\n",
      "[66,   700] loss: 0.822\n",
      "[67,   100] loss: 0.790\n",
      "[67,   200] loss: 0.768\n",
      "[67,   300] loss: 0.783\n",
      "[67,   400] loss: 0.805\n",
      "[67,   500] loss: 0.810\n",
      "[67,   600] loss: 0.804\n",
      "[67,   700] loss: 0.828\n",
      "[68,   100] loss: 0.730\n",
      "[68,   200] loss: 0.785\n",
      "[68,   300] loss: 0.805\n",
      "[68,   400] loss: 0.779\n",
      "[68,   500] loss: 0.818\n",
      "[68,   600] loss: 0.834\n",
      "[68,   700] loss: 0.817\n",
      "[69,   100] loss: 0.779\n",
      "[69,   200] loss: 0.773\n",
      "[69,   300] loss: 0.808\n",
      "[69,   400] loss: 0.837\n",
      "[69,   500] loss: 0.832\n",
      "[69,   600] loss: 0.825\n",
      "[69,   700] loss: 0.803\n",
      "[70,   100] loss: 0.773\n",
      "[70,   200] loss: 0.767\n",
      "[70,   300] loss: 0.798\n",
      "[70,   400] loss: 0.802\n",
      "[70,   500] loss: 0.799\n",
      "[70,   600] loss: 0.816\n",
      "[70,   700] loss: 0.845\n",
      "[71,   100] loss: 0.792\n",
      "[71,   200] loss: 0.762\n",
      "[71,   300] loss: 0.798\n",
      "[71,   400] loss: 0.778\n",
      "[71,   500] loss: 0.832\n",
      "[71,   600] loss: 0.794\n",
      "[71,   700] loss: 0.817\n",
      "[72,   100] loss: 0.765\n",
      "[72,   200] loss: 0.790\n",
      "[72,   300] loss: 0.812\n",
      "[72,   400] loss: 0.813\n",
      "[72,   500] loss: 0.802\n",
      "[72,   600] loss: 0.791\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ba6a64e85dac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fa022758e53c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs) \n",
    "        loss =  criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "        \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-08T01:30:16.412413Z",
     "start_time": "2020-10-08T01:29:48.643808Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 40.600000 %\n",
      "Accuracy of   car : 52.300000 %\n",
      "Accuracy of  bird : 58.400000 %\n",
      "Accuracy of   cat : 34.700000 %\n",
      "Accuracy of  deer : 52.200000 %\n",
      "Accuracy of   dog : 20.800000 %\n",
      "Accuracy of  frog : 93.500000 %\n",
      "Accuracy of horse : 57.300000 %\n",
      "Accuracy of  ship : 56.800000 %\n",
      "Accuracy of truck : 58.000000 %\n",
      "Mean Accuracy :  52.46\n"
     ]
    }
   ],
   "source": [
    "class_correct = np.zeros(10)\n",
    "class_total = np.zeros(10)\n",
    "\n",
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2f %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "print('Mean Accuracy : ', 100*np.sum(class_correct)/np.sum(class_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
