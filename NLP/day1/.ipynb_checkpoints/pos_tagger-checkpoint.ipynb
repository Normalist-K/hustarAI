{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T05:12:00.803589Z",
     "start_time": "2020-10-19T05:12:00.677681Z"
    },
    "id": "SAt8DRxd5IbJ"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "def sent_processing(lines):\n",
    "\n",
    "    if isinstance(lines, list):\n",
    "        lines = [line.strip().split(\" \") for line in lines]\n",
    "\n",
    "        corpus = []\n",
    "        for line in lines:\n",
    "            sent = []\n",
    "            for word in line:\n",
    "                word = tuple(word.rsplit(\"/\", 1))\n",
    "                sent.append(word)\n",
    "            corpus.append(sent)\n",
    "\n",
    "        return corpus\n",
    "\n",
    "    elif isinstance(lines, str):\n",
    "        line = []\n",
    "        for word in lines.strip().split(\" \"):\n",
    "            word = tuple(word.rsplit(\"/\", 1))\n",
    "            line.append(word)\n",
    "        return line\n",
    "\n",
    "    else:\n",
    "        print(\"wrong type of input sentence\")\n",
    "        exit(1)\n",
    "\n",
    "    \n",
    "with open(\"corpus.txt\", \"r\", encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "corpus = sent_processing(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T05:19:50.127297Z",
     "start_time": "2020-10-19T05:19:50.108371Z"
    },
    "id": "C-jGis_J5IbO"
   },
   "outputs": [],
   "source": [
    "def train(corpus):\n",
    "\n",
    "    def bigram_count(sent):\n",
    "        poslist = [pos for _, pos in sent] # [NN, VBD, DT, NN]\n",
    "        return [(pos0, pos1) for pos0, pos1 in zip(poslist, poslist[1:])]\n",
    "\n",
    "    pos2words_freq = defaultdict(lambda: defaultdict(int)) # number of (word, tag)\n",
    "    trans_freq = defaultdict(int) # bigram count --> (tag-1, tag)\n",
    "    bos_freq = defaultdict(int) # count for bos bigram --> number of (BOS, tag)\n",
    "\n",
    "    # sent format: [(word, tag), (word, tag), ....)]\n",
    "    for sent in corpus: # counting\n",
    "        for word, pos in sent:\n",
    "            pos2words_freq[pos][word] +=1\n",
    "\n",
    "        for bigram in bigram_count(sent):\n",
    "            trans_freq[bigram] +=1\n",
    "\n",
    "        bos_freq[sent[0][1]] +=1 # number of (BOS, tag) bigram\n",
    "        trans_freq[(sent[-1][1], 'EOS')] +=1 # number of (tag, EOS) bigram\n",
    "\n",
    "    # obervation p(x|y) - emission prob.\n",
    "    base = {pos:sum(words.values()) for pos, words in pos2words_freq.items()} # P(y) for every y (count for each tag)\n",
    "    \n",
    "    pos2words_prob =  defaultdict(lambda: defaultdict(int)) # log(p(x, y)/p(y)) for every (x, y)\n",
    "    # practice 1: emission prob tables: log(p(x, y)/p(y))\n",
    "    for pos, words in pos2words_freq.items():\n",
    "        for word, count in words.items():\n",
    "            pos2words_prob[pos][word] = math.log(count / base[pos]) \n",
    "    \n",
    "    # practice 2 : transition prob tables: log(p(y_k|p_(k-1)))\n",
    "    base = defaultdict(int)\n",
    "    for (pos0, pos), count in trans_freq.items():\n",
    "        base[pos0] += count\n",
    "    \n",
    "    trans_prob = {trans: math.log(count/base[trans[0]])\n",
    "                  for trans, count\n",
    "                  in trans_freq.items()}\n",
    "    \n",
    "    # BOS\n",
    "    base = sum(bos_freq.values()) # p(BOS) --> 100 + 200 + 55 + .... + \n",
    "    bos_prob = {pos: math.log(count/base) for pos, count in bos_freq.items()} # P(tag|BOS) \n",
    "\n",
    "    return pos2words_prob, trans_prob, bos_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T05:20:16.119797Z",
     "start_time": "2020-10-19T05:20:16.022315Z"
    },
    "id": "xPdpw8M05IbT",
    "outputId": "7fe6f08f-9d80-4691-bf1b-cb57233fd708"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명사 라면의 확률: -9.427948631791715\n",
      "연결어미 라면의 확률: -5.6937321388027\n"
     ]
    }
   ],
   "source": [
    "pos2words, trans, bos = train(corpus)\n",
    "\n",
    "print('명사 라면의 확률:', pos2words['CMC']['라면']) # 명사 '라면'의 확률 (신라면, 진라면 등.)\n",
    "print('연결어미 라면의 확률:', pos2words['fmoc']['라면']) # 연결어미 '라면'의 확률 (~ 이라면)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T05:41:48.528699Z",
     "start_time": "2020-10-19T05:41:48.507849Z"
    },
    "id": "Y9ur0ffn5Ibd"
   },
   "outputs": [],
   "source": [
    "class HMM_tagger(object):\n",
    "    def __init__(self, pos2words, trans, bos):\n",
    "        self.pos2words = pos2words\n",
    "        self.trans = trans\n",
    "        self.bos = bos\n",
    "        self.unk = -15 # penalty of unknown word \n",
    "        self.eos ='EOS'\n",
    "        \n",
    "    # sent format: [(word, tag), (word, tag), ....)]\n",
    "    def sent_log_prob(self, sent):\n",
    "        # emission prob.\n",
    "        \n",
    "        log_prob = sum([self.pos2words.get(tag, {}).get(word, self.unk)\n",
    "                        for word, tag in sent]) # get emission prob. for each (w, t), otherwise unk value\n",
    "\n",
    "#         log_prob = 0\n",
    "#         for word, tag in sent:\n",
    "#             lob_prob += self.pos2words.get(tag, {}).get(word, self.unk)\n",
    "        \n",
    "        # bos\n",
    "        log_prob += self.bos.get(sent[0][1], self.unk) # get BOS prob for the first (w, t)\n",
    "\n",
    "        # transition prob.\n",
    "        # sent: [(w_1, t_1), (w_2, t_2), ....)]\n",
    "        # sent[1:]: [(w_2, t_2), (w_3, t_3), ....)]\n",
    "        bigrams = [(t0, t1) for (_, t0), (_, t1) in zip(sent, sent[1:])] # every bigram in sentence\n",
    "        log_prob += sum([self.trans.get(bigram, self.unk) for bigram in bigrams]) # add transition prob here\n",
    "\n",
    "        # eos\n",
    "        log_prob += self.trans.get(\n",
    "            (sent[-1][1], self.eos), self.unk)\n",
    "\n",
    "        # length norm.\n",
    "        log_prob /= len(sent)\n",
    "\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-19T05:41:49.436390Z",
     "start_time": "2020-10-19T05:41:49.425896Z"
    },
    "id": "xkFgz27s5Ibh",
    "outputId": "9ee6b0bf-e66b-47e7-ff3c-9d8d728fb1ff",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감기/CMC 는/fjb 줄이/YBD 다/fmof ./g: -5.489636\n",
      "감기/fmotg 는/fjb 줄/CMC 이다/fjj ./g: -14.037157\n"
     ]
    }
   ],
   "source": [
    "tagger = HMM_tagger(pos2words, trans, bos)\n",
    "test_sent1= \"감기/CMC 는/fjb 줄이/YBD 다/fmof ./g\"\n",
    "test_sent2= \"감기/fmotg 는/fjb 줄/CMC 이다/fjj ./g\"\n",
    "print(\"%s: %f\" % (test_sent1, tagger.sent_log_prob(sent_processing(test_sent1))))\n",
    "print(\"%s: %f\" % (test_sent2, tagger.sent_log_prob(sent_processing(test_sent2))))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pos_tagger.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
